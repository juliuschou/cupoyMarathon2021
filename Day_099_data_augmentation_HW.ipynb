{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 請使用 ImageDataGenerator 來進行 Cifar-10 資料集的訓練，並觀察不同的圖像增強方法是否會顯著影響訓練結果，作業請直接提交Day099_data_augmentation.ipynb\n",
    "\n",
    "> 經過實驗發現 (1) 的 Test accuracy: 0.72 比 (2) 的 Test accuracy: 0.66 還要好\n",
    "> (1) ImageDataGenerator(rotation_range=15, width_shift_range=0.1,height_shift_range=0.1,\n",
    "                                   shear_range=0.1, zoom_range=0.1,\n",
    "                                   horizontal_flip=True)\n",
    "> (2) ImageDataGenerator(rotation_range=40, width_shift_range=0.2, height_shift_range=0.2,\n",
    "    shear_range=0.2, zoom_range=0.2, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此函數會幫我們把多張影像畫成一張多宮格圖\n",
    "def img_combine(img, ncols=8, size=1, path=False):\n",
    "    from math import ceil\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    nimg = len(img)\n",
    "    nrows = int(ceil(nimg/ncols))\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, sharey=True, figsize=(ncols*size,nrows*size))\n",
    "    if nrows == 0:\n",
    "        return\n",
    "    elif ncols == 1:\n",
    "        for r, ax in zip(np.arange(nrows), axes):\n",
    "            nth=r\n",
    "            if nth < nimg:\n",
    "                ax.imshow(img[nth], cmap='rainbow', vmin=0, vmax=1)\n",
    "                \n",
    "            ax.set_axis_off()\n",
    "    elif nrows == 1:\n",
    "        for c, ax in zip(np.arange(ncols), axes):\n",
    "            nth=c\n",
    "            if nth < nimg:\n",
    "                ax.imshow(img[nth], cmap='rainbow', vmin=0, vmax=1)\n",
    "            ax.set_axis_off()\n",
    "    else:\n",
    "        for r, row in zip(np.arange(nrows), axes):\n",
    "            for c, ax in zip(np.arange(ncols), row):\n",
    "                nth=r*ncols+c\n",
    "                if nth < nimg:\n",
    "                    ax.imshow(img[nth], cmap='rainbow', vmin=0, vmax=1)\n",
    "                ax.set_axis_off()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取 Cifar-10 資料集\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print(f'x_train.shape: {x_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取前 32 張圖片做視覺化\n",
    "images = x_train[:32]\n",
    "img_combine(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立 ImageDataGenerator，並指定我們要做資料增強的數值範圍\n",
    "data_generator = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意！！ ImageDataGenerator 是一個 Generator (生成器)! 對 Generator 不熟悉的同學請回到 Day098 做複習。\n",
    "# 使用 .flow 後，就會對我們的影像進行增強，再 call next 取出 generator 的圖像。(shuffle=False 因為我們希望圖像的順序不要改變，方便觀察。實際訓練時預設是 shuffle=True) \n",
    "augmented_iamges = next(data_generator.flow(images, shuffle=False))\n",
    "img_combine(augmented_iamges.astype(\"int\")) # 注意在訓練時神經網路時，圖像資料必須要是 float32，但在做視覺化時要轉為 int 才能順利畫圖。所以為了畫圖才把資料轉為 int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因為隨機性的關係，所以一樣的圖像再經過一次 generator 後的結果不一定相同\n",
    "augmented_iamges = next(data_generator.flow(images, shuffle=False))\n",
    "img_combine(augmented_iamges.astype(\"int\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "請使用 ImageDataGenerator 來進行 Cifar-10 資料集的訓練，並觀察不同的圖像增強方法是否會顯著影響訓練結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-03 15:24:00.423736: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-03 15:24:00.423775: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128 # batch 的大小，如果出現 OOM error，請降低這個值\n",
    "num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n",
    "epochs = 10 # 訓練的 epochs 數量\n",
    "\n",
    "# 讀取 Cifar-10 資料集\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print(f'x_train.shape: {x_train.shape}')\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "896\n",
      "9248\n",
      "18496\n",
      "36928\n",
      "flatter: 1600\n",
      "dense_1: 819712\n",
      "dense_4: 5130\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 890,410\n",
      "Trainable params: 890,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-03 15:24:08.320017: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-03 15:24:08.320073: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-03 15:24:08.320111: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (11402.pyspark3): /proc/driver/nvidia/version does not exist\n",
      "2021-12-03 15:24:08.320434: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# chanel*(kernel)*filters+bias: chanel=3, kernel=(3,3), filters=32, bias=32\n",
    "print(3*(3*3)*32+32) \n",
    "model.add(Conv2D(32, (3,3), padding='same', \n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# previous outputs * (kernel) * filters + bias: previous outputs=32, kernel=(3,3), filters=32, bias=32\n",
    "print(32*(3*3)*32+32) \n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# previous outputs * (kernel) * filters + bias: previous outputs=32, kernel=(3,3), filters=64, bias=64\n",
    "print(32*(3*3)*64+64)\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# previous outputs * (kernel) * filters + bias: previous outputs=64, kernel=(3,3), filters=64, bias=64\n",
    "print(64*(3*3)*64+64)\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "print(f'flatter: {5*5*64}')\n",
    "model.add(Flatten())\n",
    "\n",
    "print(f'dense_1: {1600*512+512}')\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# previous outputs * dense neurons + bias\n",
    "print(f'dense_4: {512*10+10}')\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()     \n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tensorflow.keras.optimizers.RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (50000, 32, 32, 3)\n",
      "x_test.shape: (10000, 32, 32, 3)\n",
      "y_train.shape: (50000, 10)\n",
      "y_test.shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(f'x_train.shape: {x_train.shape}')\n",
    "print(f'x_test.shape: {x_test.shape}')\n",
    "print(f'y_train.shape: {y_train.shape}')\n",
    "print(f'y_test.shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanzi/ml/cupoyMarathon/lib/python3.8/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2021-12-03 15:24:15.617876: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 66s 168ms/step - loss: 1.9487 - accuracy: 0.2828 - val_loss: 1.5315 - val_accuracy: 0.4518\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 65s 167ms/step - loss: 1.6977 - accuracy: 0.3864 - val_loss: 1.4207 - val_accuracy: 0.4961\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 65s 166ms/step - loss: 1.5705 - accuracy: 0.4328 - val_loss: 1.5200 - val_accuracy: 0.4665\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 65s 167ms/step - loss: 1.4820 - accuracy: 0.4702 - val_loss: 1.3175 - val_accuracy: 0.5439\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 63s 161ms/step - loss: 1.4125 - accuracy: 0.4943 - val_loss: 1.2037 - val_accuracy: 0.5757\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 66s 169ms/step - loss: 1.3627 - accuracy: 0.5148 - val_loss: 1.1835 - val_accuracy: 0.5859\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 68s 173ms/step - loss: 1.3263 - accuracy: 0.5314 - val_loss: 1.0997 - val_accuracy: 0.6143\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 75s 190ms/step - loss: 1.2833 - accuracy: 0.5450 - val_loss: 1.0307 - val_accuracy: 0.6359\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 73s 187ms/step - loss: 1.2630 - accuracy: 0.5536 - val_loss: 1.0643 - val_accuracy: 0.6224\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 70s 178ms/step - loss: 1.2419 - accuracy: 0.5655 - val_loss: 0.9805 - val_accuracy: 0.6628\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.9805 - accuracy: 0.6628\n",
      "Test loss: 0.9805282950401306\n",
      "Test accuracy: 0.6628000140190125\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "\n",
    "train_datagen.fit(x_train)\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "model.fit_generator(train_datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "         validation_data=(x_test, y_test),\n",
    "            epochs=epochs)\n",
    "\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 65s 167ms/step - loss: 1.6224 - accuracy: 0.4298 - val_loss: 1.3406 - val_accuracy: 0.5443\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 64s 163ms/step - loss: 1.4496 - accuracy: 0.4955 - val_loss: 1.4717 - val_accuracy: 0.5200\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 65s 166ms/step - loss: 1.3739 - accuracy: 0.5245 - val_loss: 1.2541 - val_accuracy: 0.5635\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 65s 165ms/step - loss: 1.3412 - accuracy: 0.5364 - val_loss: 1.0494 - val_accuracy: 0.6278\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 65s 166ms/step - loss: 1.3074 - accuracy: 0.5467 - val_loss: 1.0866 - val_accuracy: 0.6488\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 65s 166ms/step - loss: 1.2887 - accuracy: 0.5557 - val_loss: 1.1378 - val_accuracy: 0.6280\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 68s 173ms/step - loss: 1.2648 - accuracy: 0.5640 - val_loss: 1.1174 - val_accuracy: 0.6227\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 68s 174ms/step - loss: 1.2498 - accuracy: 0.5684 - val_loss: 0.9594 - val_accuracy: 0.6707\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 73s 187ms/step - loss: 1.2413 - accuracy: 0.5731 - val_loss: 1.0077 - val_accuracy: 0.6581\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 68s 174ms/step - loss: 1.2428 - accuracy: 0.5733 - val_loss: 1.0508 - val_accuracy: 0.6307\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.0508 - accuracy: 0.6307\n",
      "Test loss: 1.0508065223693848\n",
      "Test accuracy: 0.6306999921798706\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "train_datagen.fit(x_train)\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "model.fit_generator(train_datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "         validation_data=(x_test, y_test),\n",
    "            epochs=epochs)\n",
    "\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 68s 174ms/step - loss: 1.4616 - accuracy: 0.4919 - val_loss: 1.1141 - val_accuracy: 0.6171\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 68s 173ms/step - loss: 1.4328 - accuracy: 0.5026 - val_loss: 1.1414 - val_accuracy: 0.6107\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 68s 175ms/step - loss: 1.4210 - accuracy: 0.5059 - val_loss: 1.1349 - val_accuracy: 0.6009\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 68s 175ms/step - loss: 1.4118 - accuracy: 0.5078 - val_loss: 1.4061 - val_accuracy: 0.5646\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 67s 172ms/step - loss: 1.4041 - accuracy: 0.5134 - val_loss: 1.4052 - val_accuracy: 0.5439\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 67s 171ms/step - loss: 1.3957 - accuracy: 0.5163 - val_loss: 1.0947 - val_accuracy: 0.6178\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 67s 171ms/step - loss: 1.3839 - accuracy: 0.5216 - val_loss: 1.2524 - val_accuracy: 0.5773\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 67s 172ms/step - loss: 1.3889 - accuracy: 0.5187 - val_loss: 1.1238 - val_accuracy: 0.6127\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 68s 173ms/step - loss: 1.3920 - accuracy: 0.5209 - val_loss: 1.1475 - val_accuracy: 0.6118\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 68s 174ms/step - loss: 1.3993 - accuracy: 0.5197 - val_loss: 1.1099 - val_accuracy: 0.6121\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.1099 - accuracy: 0.6121\n",
      "Test loss: 1.1098511219024658\n",
      "Test accuracy: 0.6121000051498413\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=90,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "train_datagen.fit(x_train)\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "model.fit_generator(train_datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "         validation_data=(x_test, y_test),\n",
    "            epochs=epochs)\n",
    "\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 67s 172ms/step - loss: 1.0788 - accuracy: 0.6339 - val_loss: 1.7640 - val_accuracy: 0.5150\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 67s 172ms/step - loss: 1.0282 - accuracy: 0.6552 - val_loss: 0.8523 - val_accuracy: 0.7058\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 67s 172ms/step - loss: 0.9968 - accuracy: 0.6647 - val_loss: 0.9993 - val_accuracy: 0.6789\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 68s 173ms/step - loss: 0.9833 - accuracy: 0.6666 - val_loss: 0.8503 - val_accuracy: 0.7112\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 68s 173ms/step - loss: 0.9845 - accuracy: 0.6703 - val_loss: 0.8434 - val_accuracy: 0.7091\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 68s 173ms/step - loss: 0.9735 - accuracy: 0.6743 - val_loss: 0.8715 - val_accuracy: 0.7063\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 67s 172ms/step - loss: 0.9711 - accuracy: 0.6760 - val_loss: 0.8831 - val_accuracy: 0.6924\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 69s 175ms/step - loss: 0.9727 - accuracy: 0.6763 - val_loss: 0.9275 - val_accuracy: 0.7110\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 68s 173ms/step - loss: 0.9568 - accuracy: 0.6795 - val_loss: 0.8995 - val_accuracy: 0.6959\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 68s 174ms/step - loss: 0.9605 - accuracy: 0.6781 - val_loss: 0.9902 - val_accuracy: 0.6832\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.9902 - accuracy: 0.6832\n",
      "Test loss: 0.9901849627494812\n",
      "Test accuracy: 0.6832000017166138\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    )\n",
    "\n",
    "train_datagen.fit(x_train)\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "model.fit_generator(train_datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "         validation_data=(x_test, y_test),\n",
    "            epochs=epochs)\n",
    "\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 68s 173ms/step - loss: 0.9695 - accuracy: 0.6771 - val_loss: 0.8320 - val_accuracy: 0.7280\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 68s 173ms/step - loss: 0.9656 - accuracy: 0.6793 - val_loss: 0.8588 - val_accuracy: 0.7072\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 69s 176ms/step - loss: 0.9659 - accuracy: 0.6795 - val_loss: 0.8070 - val_accuracy: 0.7336\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 68s 175ms/step - loss: 0.9651 - accuracy: 0.6798 - val_loss: 0.9397 - val_accuracy: 0.6941\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 69s 175ms/step - loss: 0.9687 - accuracy: 0.6791 - val_loss: 0.8345 - val_accuracy: 0.7248\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 69s 177ms/step - loss: 0.9705 - accuracy: 0.6789 - val_loss: 0.8378 - val_accuracy: 0.7214\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 68s 173ms/step - loss: 0.9735 - accuracy: 0.6793 - val_loss: 0.7720 - val_accuracy: 0.7491\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 68s 174ms/step - loss: 0.9700 - accuracy: 0.6800 - val_loss: 0.8712 - val_accuracy: 0.7196\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 68s 174ms/step - loss: 0.9722 - accuracy: 0.6791 - val_loss: 0.8307 - val_accuracy: 0.7369\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 68s 174ms/step - loss: 0.9753 - accuracy: 0.6794 - val_loss: 0.8306 - val_accuracy: 0.7290\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.8306 - accuracy: 0.7290\n",
      "Test loss: 0.8305706977844238\n",
      "Test accuracy: 0.7289999723434448\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   shear_range=0.1,\n",
    "                                   zoom_range=0.1,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "train_datagen.fit(x_train)\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "model.fit_generator(train_datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "         validation_data=(x_test, y_test),\n",
    "            epochs=epochs)\n",
    "\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    i = 0\n",
    "    while 1:\n",
    "        i += 1\n",
    "        yield i\n",
    "for item in generator():\n",
    "    print(item)\n",
    "    if item > 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
