{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "import itertools\n",
    "import tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128 # batch 的大小，如果出現 OOM error，請降低這個值\n",
    "num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n",
    "epochs = 10 # 訓練的 epochs 數量\n",
    "\n",
    "# 讀取資料並檢視\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# 對 label 進行 one-hot encoding (y_trian 原本是純數字)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 首先我們使用一般的 DNN (MLP) 來訓練\n",
    "由於 DNN 只能輸入一維的資料，我們要先將影像進行攤平，若 (50000, 32, 32, 3) 的影像，攤平後會變成 (50000, 32*32*3) = (50000, 3072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# 將資料攤平成一維資料\n",
    "x_train = x_train.reshape(50000, 3072) \n",
    "x_test = x_test.reshape(10000, 3072)\n",
    "\n",
    "# 將資料變為 float32 並標準化\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,841,162\n",
      "Trainable params: 1,841,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 2.1639 - acc: 0.2466 - val_loss: 1.8197 - val_acc: 0.3513\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.8590 - acc: 0.3265 - val_loss: 1.8009 - val_acc: 0.3321\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.7833 - acc: 0.3575 - val_loss: 1.6762 - val_acc: 0.4060\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.7327 - acc: 0.3780 - val_loss: 1.7022 - val_acc: 0.3977\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6959 - acc: 0.3896 - val_loss: 1.6314 - val_acc: 0.4194\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.6697 - acc: 0.3993 - val_loss: 1.6231 - val_acc: 0.4264\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.6483 - acc: 0.4088 - val_loss: 1.6370 - val_acc: 0.4051\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6299 - acc: 0.4182 - val_loss: 1.5738 - val_acc: 0.4466\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6143 - acc: 0.4241 - val_loss: 1.5522 - val_acc: 0.4561\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.6003 - acc: 0.4278 - val_loss: 1.5236 - val_acc: 0.4728\n",
      "Test loss: 1.5236255004882813\n",
      "Test accuracy: 0.4728\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 接下來我們使用 CNN 來訓練神經網路\n",
    "CNN 的原理非常適合處理影像類的資料，就讓我們來看看，同樣的訓練條件，CNN 是否顯著優於 DNN 呢?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.7666 - acc: 0.3592 - val_loss: 1.3987 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.3330 - acc: 0.5265 - val_loss: 1.1460 - val_acc: 0.5954\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.1267 - acc: 0.6023 - val_loss: 1.0026 - val_acc: 0.6478\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.9935 - acc: 0.6526 - val_loss: 0.9748 - val_acc: 0.6595\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.8920 - acc: 0.6898 - val_loss: 0.8119 - val_acc: 0.7186\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.8237 - acc: 0.7140 - val_loss: 0.7926 - val_acc: 0.7251\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.7667 - acc: 0.7316 - val_loss: 0.7685 - val_acc: 0.7384\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.7274 - acc: 0.7489 - val_loss: 0.9322 - val_acc: 0.6901\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.6910 - acc: 0.7588 - val_loss: 0.7872 - val_acc: 0.7317\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.6736 - acc: 0.7655 - val_loss: 0.7365 - val_acc: 0.7479\n",
      "Test loss: 0.7365292016983033\n",
      "Test accuracy: 0.7479\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 同樣運算 10 個 epochs，但 CNN 在 test data 的準確率顯著優於 DNN!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "1. 請試著調整各個超參數，並說明那些超參數對於結果有明顯的影響?\n",
    "2. CNN 與 DNN 哪個模型的參數數量比較多? 造成參數的數量不同的原因在哪?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 512 \n",
    "NUM_CLASSES = 10 # 類別的數量，Cifar 10 共有 10 個類別\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_set = [keras.optimizers.gradient_descent_v2.SGD(learning_rate=LEARNING_RATE, nesterov=True, momentum=0.95),\n",
    "                 tensorflow.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                 tensorflow.keras.optimizers.RMSprop(learning_rate=LEARNING_RATE)]\n",
    "\n",
    "\"\"\"Code Here\n",
    "建立實驗的比較組合\n",
    "\"\"\"\n",
    "epochs = [10, 20]\n",
    "kernels = [(3,3), (5, 5)]\n",
    "pool_sizes = [(2,2), (3, 3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of exp: 0, optimizer:SGD, kernel: (3, 3), epochs: 10, pool_size:(2, 2)\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_180 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_265 (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_181 (Conv2D)          (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_266 (Activation)  (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_90 (MaxPooling (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_131 (Dropout)        (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_182 (Conv2D)          (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_267 (Activation)  (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_183 (Conv2D)          (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_268 (Activation)  (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_91 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_132 (Dropout)        (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_43 (Flatten)         (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_269 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_133 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_270 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "98/98 [==============================] - 129s 1s/step - loss: 2.3001 - accuracy: 0.1096 - val_loss: 2.2924 - val_accuracy: 0.1188\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 136s 1s/step - loss: 2.2788 - accuracy: 0.1332 - val_loss: 2.2469 - val_accuracy: 0.1755\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 137s 1s/step - loss: 2.1892 - accuracy: 0.1830 - val_loss: 2.0882 - val_accuracy: 0.2457\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 95s 969ms/step - loss: 2.0793 - accuracy: 0.2242 - val_loss: 2.0124 - val_accuracy: 0.2668\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 96s 977ms/step - loss: 2.0367 - accuracy: 0.2429 - val_loss: 1.9793 - val_accuracy: 0.2862\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 94s 962ms/step - loss: 2.0073 - accuracy: 0.2592 - val_loss: 1.9520 - val_accuracy: 0.2941\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 87s 883ms/step - loss: 1.9803 - accuracy: 0.2696 - val_loss: 1.9204 - val_accuracy: 0.3093\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 102s 1s/step - loss: 1.9509 - accuracy: 0.2881 - val_loss: 1.8791 - val_accuracy: 0.3258\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 95s 969ms/step - loss: 1.9076 - accuracy: 0.3056 - val_loss: 1.8291 - val_accuracy: 0.3573\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 80s 812ms/step - loss: 1.8559 - accuracy: 0.3274 - val_loss: 1.7792 - val_accuracy: 0.3788\n",
      "test_loss: 1.7792236804962158, test_accuracy: 0.37880000472068787\n",
      "Numbers of exp: 1, optimizer:SGD, kernel: (3, 3), epochs: 10, pool_size:(3, 3)\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_184 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_271 (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_185 (Conv2D)          (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_272 (Activation)  (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_92 (MaxPooling (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_134 (Dropout)        (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_186 (Conv2D)          (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_273 (Activation)  (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_187 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_274 (Activation)  (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_93 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_135 (Dropout)        (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_44 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_275 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_136 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_276 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 202,282\n",
      "Trainable params: 202,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "98/98 [==============================] - 57s 582ms/step - loss: 2.3038 - accuracy: 0.1061 - val_loss: 2.2995 - val_accuracy: 0.1312\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 61s 625ms/step - loss: 2.2983 - accuracy: 0.1170 - val_loss: 2.2936 - val_accuracy: 0.1733\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 61s 624ms/step - loss: 2.2893 - accuracy: 0.1382 - val_loss: 2.2789 - val_accuracy: 0.1485\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 58s 587ms/step - loss: 2.2640 - accuracy: 0.1483 - val_loss: 2.2322 - val_accuracy: 0.1764\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 54s 552ms/step - loss: 2.2007 - accuracy: 0.1701 - val_loss: 2.1370 - val_accuracy: 0.2273\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 53s 541ms/step - loss: 2.1232 - accuracy: 0.1918 - val_loss: 2.0574 - val_accuracy: 0.2412\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 53s 541ms/step - loss: 2.0812 - accuracy: 0.2099 - val_loss: 2.0304 - val_accuracy: 0.2504\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 53s 537ms/step - loss: 2.0556 - accuracy: 0.2184 - val_loss: 2.0039 - val_accuracy: 0.2563\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 53s 539ms/step - loss: 2.0353 - accuracy: 0.2249 - val_loss: 1.9829 - val_accuracy: 0.2570\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 52s 534ms/step - loss: 2.0147 - accuracy: 0.2330 - val_loss: 1.9613 - val_accuracy: 0.2652\n",
      "test_loss: 1.9612817764282227, test_accuracy: 0.2651999890804291\n",
      "Numbers of exp: 2, optimizer:SGD, kernel: (3, 3), epochs: 20, pool_size:(2, 2)\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_188 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_277 (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_189 (Conv2D)          (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_278 (Activation)  (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_94 (MaxPooling (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_137 (Dropout)        (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_190 (Conv2D)          (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_279 (Activation)  (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_191 (Conv2D)          (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_280 (Activation)  (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_95 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_138 (Dropout)        (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_45 (Flatten)         (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_281 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_139 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_282 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "98/98 [==============================] - 75s 750ms/step - loss: 2.2998 - accuracy: 0.1120 - val_loss: 2.2895 - val_accuracy: 0.1261\n",
      "Epoch 2/20\n",
      "98/98 [==============================] - 73s 747ms/step - loss: 2.2722 - accuracy: 0.1361 - val_loss: 2.2324 - val_accuracy: 0.2037\n",
      "Epoch 3/20\n",
      "98/98 [==============================] - 73s 748ms/step - loss: 2.1584 - accuracy: 0.2016 - val_loss: 2.0312 - val_accuracy: 0.2670\n",
      "Epoch 4/20\n",
      "98/98 [==============================] - 73s 747ms/step - loss: 2.0432 - accuracy: 0.2427 - val_loss: 1.9758 - val_accuracy: 0.2859\n",
      "Epoch 5/20\n",
      "98/98 [==============================] - 73s 747ms/step - loss: 2.0007 - accuracy: 0.2621 - val_loss: 1.9423 - val_accuracy: 0.2992\n",
      "Epoch 6/20\n",
      "98/98 [==============================] - 73s 747ms/step - loss: 1.9652 - accuracy: 0.2811 - val_loss: 1.9045 - val_accuracy: 0.3268\n",
      "Epoch 7/20\n",
      "98/98 [==============================] - 73s 748ms/step - loss: 1.9227 - accuracy: 0.2993 - val_loss: 1.8518 - val_accuracy: 0.3450\n",
      "Epoch 8/20\n",
      "98/98 [==============================] - 73s 746ms/step - loss: 1.8815 - accuracy: 0.3160 - val_loss: 1.8041 - val_accuracy: 0.3611\n",
      "Epoch 9/20\n",
      "98/98 [==============================] - 73s 748ms/step - loss: 1.8319 - accuracy: 0.3362 - val_loss: 1.7494 - val_accuracy: 0.3801\n",
      "Epoch 10/20\n",
      "98/98 [==============================] - 73s 746ms/step - loss: 1.7873 - accuracy: 0.3472 - val_loss: 1.7039 - val_accuracy: 0.3892\n",
      "Epoch 11/20\n",
      "98/98 [==============================] - 73s 746ms/step - loss: 1.7439 - accuracy: 0.3617 - val_loss: 1.6619 - val_accuracy: 0.4014\n",
      "Epoch 12/20\n",
      "98/98 [==============================] - 73s 745ms/step - loss: 1.7047 - accuracy: 0.3740 - val_loss: 1.6172 - val_accuracy: 0.4119\n",
      "Epoch 13/20\n",
      "98/98 [==============================] - 73s 747ms/step - loss: 1.6707 - accuracy: 0.3864 - val_loss: 1.5811 - val_accuracy: 0.4277\n",
      "Epoch 14/20\n",
      "98/98 [==============================] - 73s 749ms/step - loss: 1.6432 - accuracy: 0.3976 - val_loss: 1.5589 - val_accuracy: 0.4330\n",
      "Epoch 15/20\n",
      "98/98 [==============================] - 73s 743ms/step - loss: 1.6122 - accuracy: 0.4083 - val_loss: 1.5835 - val_accuracy: 0.4222\n",
      "Epoch 16/20\n",
      "98/98 [==============================] - 73s 746ms/step - loss: 1.5853 - accuracy: 0.4208 - val_loss: 1.4988 - val_accuracy: 0.4499\n",
      "Epoch 17/20\n",
      "98/98 [==============================] - 73s 746ms/step - loss: 1.5641 - accuracy: 0.4294 - val_loss: 1.4771 - val_accuracy: 0.4610\n",
      "Epoch 18/20\n",
      "98/98 [==============================] - 73s 748ms/step - loss: 1.5419 - accuracy: 0.4388 - val_loss: 1.4515 - val_accuracy: 0.4710\n",
      "Epoch 19/20\n",
      "98/98 [==============================] - 73s 745ms/step - loss: 1.5207 - accuracy: 0.4483 - val_loss: 1.4546 - val_accuracy: 0.4758\n",
      "Epoch 20/20\n",
      "98/98 [==============================] - 76s 773ms/step - loss: 1.5011 - accuracy: 0.4556 - val_loss: 1.4179 - val_accuracy: 0.4846\n",
      "test_loss: 1.417934536933899, test_accuracy: 0.4846000075340271\n",
      "Numbers of exp: 3, optimizer:SGD, kernel: (3, 3), epochs: 20, pool_size:(3, 3)\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_192 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_283 (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_193 (Conv2D)          (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_284 (Activation)  (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_96 (MaxPooling (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_140 (Dropout)        (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_194 (Conv2D)          (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_285 (Activation)  (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_195 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_286 (Activation)  (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_97 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_141 (Dropout)        (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_46 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_287 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_142 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_288 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 202,282\n",
      "Trainable params: 202,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "98/98 [==============================] - 53s 542ms/step - loss: 2.3038 - accuracy: 0.1029 - val_loss: 2.2997 - val_accuracy: 0.1434\n",
      "Epoch 2/20\n",
      "98/98 [==============================] - 53s 536ms/step - loss: 2.2996 - accuracy: 0.1129 - val_loss: 2.2969 - val_accuracy: 0.1865\n",
      "Epoch 3/20\n",
      "98/98 [==============================] - 53s 539ms/step - loss: 2.2956 - accuracy: 0.1231 - val_loss: 2.2924 - val_accuracy: 0.1891\n",
      "Epoch 4/20\n",
      "98/98 [==============================] - 52s 534ms/step - loss: 2.2881 - accuracy: 0.1350 - val_loss: 2.2804 - val_accuracy: 0.1707\n",
      "Epoch 5/20\n",
      "98/98 [==============================] - 52s 533ms/step - loss: 2.2683 - accuracy: 0.1536 - val_loss: 2.2447 - val_accuracy: 0.1888\n",
      "Epoch 6/20\n",
      "98/98 [==============================] - 53s 537ms/step - loss: 2.2133 - accuracy: 0.1704 - val_loss: 2.1512 - val_accuracy: 0.2344\n",
      "Epoch 7/20\n",
      "98/98 [==============================] - 53s 537ms/step - loss: 2.1308 - accuracy: 0.1920 - val_loss: 2.0664 - val_accuracy: 0.2427\n",
      "Epoch 8/20\n",
      "98/98 [==============================] - 53s 538ms/step - loss: 2.0864 - accuracy: 0.2137 - val_loss: 2.0390 - val_accuracy: 0.2502\n",
      "Epoch 9/20\n",
      "98/98 [==============================] - 52s 534ms/step - loss: 2.0623 - accuracy: 0.2257 - val_loss: 2.0170 - val_accuracy: 0.2571\n",
      "Epoch 10/20\n",
      "98/98 [==============================] - 52s 535ms/step - loss: 2.0427 - accuracy: 0.2325 - val_loss: 1.9946 - val_accuracy: 0.2715\n",
      "Epoch 11/20\n",
      "98/98 [==============================] - 53s 537ms/step - loss: 2.0209 - accuracy: 0.2424 - val_loss: 1.9745 - val_accuracy: 0.2787\n",
      "Epoch 12/20\n",
      "98/98 [==============================] - 53s 537ms/step - loss: 1.9933 - accuracy: 0.2535 - val_loss: 1.9369 - val_accuracy: 0.2900\n",
      "Epoch 13/20\n",
      "98/98 [==============================] - 53s 538ms/step - loss: 1.9592 - accuracy: 0.2650 - val_loss: 1.8927 - val_accuracy: 0.3048\n",
      "Epoch 14/20\n",
      "98/98 [==============================] - 53s 536ms/step - loss: 1.9210 - accuracy: 0.2808 - val_loss: 1.8488 - val_accuracy: 0.3215\n",
      "Epoch 15/20\n",
      "98/98 [==============================] - 53s 539ms/step - loss: 1.8845 - accuracy: 0.2910 - val_loss: 1.8084 - val_accuracy: 0.3388\n",
      "Epoch 16/20\n",
      "98/98 [==============================] - 52s 536ms/step - loss: 1.8481 - accuracy: 0.3035 - val_loss: 1.7728 - val_accuracy: 0.3506\n",
      "Epoch 17/20\n",
      "98/98 [==============================] - 61s 624ms/step - loss: 1.8253 - accuracy: 0.3107 - val_loss: 1.7507 - val_accuracy: 0.3624\n",
      "Epoch 18/20\n",
      "98/98 [==============================] - 60s 612ms/step - loss: 1.7990 - accuracy: 0.3207 - val_loss: 1.7228 - val_accuracy: 0.3709\n",
      "Epoch 19/20\n",
      "98/98 [==============================] - 61s 618ms/step - loss: 1.7731 - accuracy: 0.3333 - val_loss: 1.6907 - val_accuracy: 0.3772\n",
      "Epoch 20/20\n",
      "98/98 [==============================] - 60s 608ms/step - loss: 1.7545 - accuracy: 0.3399 - val_loss: 1.6679 - val_accuracy: 0.3921\n",
      "test_loss: 1.6679441928863525, test_accuracy: 0.3921000063419342\n",
      "Numbers of exp: 4, optimizer:SGD, kernel: (5, 5), epochs: 10, pool_size:(2, 2)\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_196 (Conv2D)          (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation_289 (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_197 (Conv2D)          (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_290 (Activation)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_98 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_143 (Dropout)        (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_198 (Conv2D)          (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_291 (Activation)  (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_199 (Conv2D)          (None, 10, 10, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_292 (Activation)  (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_99 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_144 (Dropout)        (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_47 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "activation_293 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_145 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_294 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,006,634\n",
      "Trainable params: 1,006,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "98/98 [==============================] - 157s 2s/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.2916 - val_accuracy: 0.1283\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 166s 2s/step - loss: 2.2611 - accuracy: 0.1423 - val_loss: 2.1720 - val_accuracy: 0.2089\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 158s 2s/step - loss: 2.1159 - accuracy: 0.2043 - val_loss: 2.0273 - val_accuracy: 0.2615\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 154s 2s/step - loss: 2.0390 - accuracy: 0.2351 - val_loss: 1.9635 - val_accuracy: 0.2822\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 157s 2s/step - loss: 1.9741 - accuracy: 0.2662 - val_loss: 1.8879 - val_accuracy: 0.3206\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 150s 2s/step - loss: 1.9038 - accuracy: 0.2908 - val_loss: 1.8242 - val_accuracy: 0.3427\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 149s 2s/step - loss: 1.8250 - accuracy: 0.3216 - val_loss: 1.7293 - val_accuracy: 0.3789\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 162s 2s/step - loss: 1.7541 - accuracy: 0.3466 - val_loss: 1.6542 - val_accuracy: 0.3950\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 160s 2s/step - loss: 1.6908 - accuracy: 0.3736 - val_loss: 1.5767 - val_accuracy: 0.4251\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 164s 2s/step - loss: 1.6395 - accuracy: 0.3943 - val_loss: 1.5344 - val_accuracy: 0.4416\n",
      "test_loss: 1.534393310546875, test_accuracy: 0.4415999948978424\n",
      "Numbers of exp: 5, optimizer:SGD, kernel: (5, 5), epochs: 10, pool_size:(3, 3)\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_200 (Conv2D)          (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation_295 (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_201 (Conv2D)          (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_296 (Activation)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_100 (MaxPoolin (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_146 (Dropout)        (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_202 (Conv2D)          (None, 9, 9, 64)          51264     \n",
      "_________________________________________________________________\n",
      "activation_297 (Activation)  (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_203 (Conv2D)          (None, 5, 5, 64)          102464    \n",
      "_________________________________________________________________\n",
      "activation_298 (Activation)  (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_101 (MaxPoolin (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_147 (Dropout)        (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_48 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "activation_299 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_148 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_300 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 220,202\n",
      "Trainable params: 220,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "98/98 [==============================] - 122s 1s/step - loss: 2.3016 - accuracy: 0.1042 - val_loss: 2.2977 - val_accuracy: 0.1103\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 134s 1s/step - loss: 2.2936 - accuracy: 0.1165 - val_loss: 2.2843 - val_accuracy: 0.1278\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 127s 1s/step - loss: 2.2660 - accuracy: 0.1377 - val_loss: 2.2198 - val_accuracy: 0.1931\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 135s 1s/step - loss: 2.1808 - accuracy: 0.1783 - val_loss: 2.1088 - val_accuracy: 0.2186\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 130s 1s/step - loss: 2.1153 - accuracy: 0.1962 - val_loss: 2.0583 - val_accuracy: 0.2242\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 119s 1s/step - loss: 2.0827 - accuracy: 0.2084 - val_loss: 2.0327 - val_accuracy: 0.2523\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 112s 1s/step - loss: 2.0514 - accuracy: 0.2216 - val_loss: 1.9922 - val_accuracy: 0.2666\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 116s 1s/step - loss: 2.0100 - accuracy: 0.2429 - val_loss: 1.9349 - val_accuracy: 0.2896\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 116s 1s/step - loss: 1.9596 - accuracy: 0.2567 - val_loss: 1.8760 - val_accuracy: 0.3108\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 127s 1s/step - loss: 1.8998 - accuracy: 0.2770 - val_loss: 1.8250 - val_accuracy: 0.3211\n",
      "test_loss: 1.8250279426574707, test_accuracy: 0.32109999656677246\n",
      "Numbers of exp: 6, optimizer:SGD, kernel: (5, 5), epochs: 20, pool_size:(2, 2)\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_204 (Conv2D)          (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation_301 (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_205 (Conv2D)          (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_302 (Activation)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_102 (MaxPoolin (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_149 (Dropout)        (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_206 (Conv2D)          (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_303 (Activation)  (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_207 (Conv2D)          (None, 10, 10, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_304 (Activation)  (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_103 (MaxPoolin (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_150 (Dropout)        (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_49 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "activation_305 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_151 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_306 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,006,634\n",
      "Trainable params: 1,006,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "98/98 [==============================] - 188s 2s/step - loss: 2.3004 - accuracy: 0.1134 - val_loss: 2.2908 - val_accuracy: 0.1229\n",
      "Epoch 2/20\n",
      "98/98 [==============================] - 165s 2s/step - loss: 2.2674 - accuracy: 0.1434 - val_loss: 2.1879 - val_accuracy: 0.1895\n",
      "Epoch 3/20\n",
      "98/98 [==============================] - 170s 2s/step - loss: 2.1179 - accuracy: 0.1932 - val_loss: 2.0182 - val_accuracy: 0.2824\n",
      "Epoch 4/20\n",
      "98/98 [==============================] - 142s 1s/step - loss: 2.0205 - accuracy: 0.2427 - val_loss: 1.9196 - val_accuracy: 0.3235\n",
      "Epoch 5/20\n",
      "98/98 [==============================] - 152s 2s/step - loss: 1.9302 - accuracy: 0.2819 - val_loss: 1.8083 - val_accuracy: 0.3511\n",
      "Epoch 6/20\n",
      "98/98 [==============================] - 200s 2s/step - loss: 1.8410 - accuracy: 0.3172 - val_loss: 1.7214 - val_accuracy: 0.3731\n",
      "Epoch 7/20\n",
      "98/98 [==============================] - 187s 2s/step - loss: 1.7770 - accuracy: 0.3406 - val_loss: 1.6719 - val_accuracy: 0.3929\n",
      "Epoch 8/20\n",
      "98/98 [==============================] - 182s 2s/step - loss: 1.7286 - accuracy: 0.3596 - val_loss: 1.6379 - val_accuracy: 0.3994\n",
      "Epoch 9/20\n",
      "98/98 [==============================] - 177s 2s/step - loss: 1.6828 - accuracy: 0.3757 - val_loss: 1.5884 - val_accuracy: 0.4179\n",
      "Epoch 10/20\n",
      "98/98 [==============================] - 158s 2s/step - loss: 1.6405 - accuracy: 0.3906 - val_loss: 1.5620 - val_accuracy: 0.4291\n",
      "Epoch 11/20\n",
      "98/98 [==============================] - 152s 2s/step - loss: 1.6050 - accuracy: 0.4087 - val_loss: 1.5046 - val_accuracy: 0.4474\n",
      "Epoch 12/20\n",
      "98/98 [==============================] - 156s 2s/step - loss: 1.5703 - accuracy: 0.4216 - val_loss: 1.4858 - val_accuracy: 0.4570\n",
      "Epoch 13/20\n",
      "98/98 [==============================] - 150s 2s/step - loss: 1.5383 - accuracy: 0.4314 - val_loss: 1.4458 - val_accuracy: 0.4709\n",
      "Epoch 14/20\n",
      "98/98 [==============================] - 143s 1s/step - loss: 1.5138 - accuracy: 0.4421 - val_loss: 1.4231 - val_accuracy: 0.4822\n",
      "Epoch 15/20\n",
      "98/98 [==============================] - 147s 1s/step - loss: 1.4877 - accuracy: 0.4505 - val_loss: 1.3999 - val_accuracy: 0.4871\n",
      "Epoch 16/20\n",
      "98/98 [==============================] - 150s 2s/step - loss: 1.4696 - accuracy: 0.4590 - val_loss: 1.3787 - val_accuracy: 0.4980\n",
      "Epoch 17/20\n",
      "98/98 [==============================] - 141s 1s/step - loss: 1.4471 - accuracy: 0.4691 - val_loss: 1.3613 - val_accuracy: 0.5053\n",
      "Epoch 18/20\n",
      "98/98 [==============================] - 135s 1s/step - loss: 1.4320 - accuracy: 0.4773 - val_loss: 1.3444 - val_accuracy: 0.5136\n",
      "Epoch 19/20\n",
      "98/98 [==============================] - 136s 1s/step - loss: 1.4114 - accuracy: 0.4843 - val_loss: 1.3415 - val_accuracy: 0.5163\n",
      "Epoch 20/20\n",
      "98/98 [==============================] - 135s 1s/step - loss: 1.3953 - accuracy: 0.4904 - val_loss: 1.3157 - val_accuracy: 0.5229\n",
      "test_loss: 1.315718650817871, test_accuracy: 0.5228999853134155\n",
      "Numbers of exp: 7, optimizer:SGD, kernel: (5, 5), epochs: 20, pool_size:(3, 3)\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_208 (Conv2D)          (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation_307 (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_209 (Conv2D)          (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_308 (Activation)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_104 (MaxPoolin (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_152 (Dropout)        (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_210 (Conv2D)          (None, 9, 9, 64)          51264     \n",
      "_________________________________________________________________\n",
      "activation_309 (Activation)  (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_211 (Conv2D)          (None, 5, 5, 64)          102464    \n",
      "_________________________________________________________________\n",
      "activation_310 (Activation)  (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_105 (MaxPoolin (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_153 (Dropout)        (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_50 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "activation_311 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_154 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_312 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 220,202\n",
      "Trainable params: 220,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "98/98 [==============================] - 101s 1s/step - loss: 2.3016 - accuracy: 0.1037 - val_loss: 2.2996 - val_accuracy: 0.1248\n",
      "Epoch 2/20\n",
      "98/98 [==============================] - 100s 1s/step - loss: 2.2979 - accuracy: 0.1184 - val_loss: 2.2933 - val_accuracy: 0.1342\n",
      "Epoch 3/20\n",
      "98/98 [==============================] - 101s 1s/step - loss: 2.2856 - accuracy: 0.1318 - val_loss: 2.2644 - val_accuracy: 0.1739\n",
      "Epoch 4/20\n",
      "98/98 [==============================] - 100s 1s/step - loss: 2.2276 - accuracy: 0.1610 - val_loss: 2.1484 - val_accuracy: 0.1935\n",
      "Epoch 5/20\n",
      "98/98 [==============================] - 101s 1s/step - loss: 2.1376 - accuracy: 0.1891 - val_loss: 2.0720 - val_accuracy: 0.2286\n",
      "Epoch 6/20\n",
      "98/98 [==============================] - 101s 1s/step - loss: 2.0923 - accuracy: 0.1998 - val_loss: 2.0336 - val_accuracy: 0.2519\n",
      "Epoch 7/20\n",
      "98/98 [==============================] - 101s 1s/step - loss: 2.0549 - accuracy: 0.2132 - val_loss: 1.9883 - val_accuracy: 0.2698\n",
      "Epoch 8/20\n",
      "98/98 [==============================] - 100s 1s/step - loss: 2.0085 - accuracy: 0.2334 - val_loss: 1.9284 - val_accuracy: 0.2887\n",
      "Epoch 9/20\n",
      "98/98 [==============================] - 101s 1s/step - loss: 1.9509 - accuracy: 0.2572 - val_loss: 1.8533 - val_accuracy: 0.3225\n",
      "Epoch 10/20\n",
      "98/98 [==============================] - 101s 1s/step - loss: 1.8906 - accuracy: 0.2763 - val_loss: 1.7908 - val_accuracy: 0.3453\n",
      "Epoch 11/20\n",
      "98/98 [==============================] - 101s 1s/step - loss: 1.8495 - accuracy: 0.2892 - val_loss: 1.8034 - val_accuracy: 0.3380\n",
      "Epoch 12/20\n",
      "98/98 [==============================] - 103s 1s/step - loss: 1.8144 - accuracy: 0.3073 - val_loss: 1.7203 - val_accuracy: 0.3707\n",
      "Epoch 13/20\n",
      "98/98 [==============================] - 101s 1s/step - loss: 1.7801 - accuracy: 0.3228 - val_loss: 1.6853 - val_accuracy: 0.3837\n",
      "Epoch 14/20\n",
      "98/98 [==============================] - 101s 1s/step - loss: 1.7515 - accuracy: 0.3409 - val_loss: 1.6860 - val_accuracy: 0.3891\n",
      "Epoch 15/20\n",
      "98/98 [==============================] - 101s 1s/step - loss: 1.7187 - accuracy: 0.3534 - val_loss: 1.6608 - val_accuracy: 0.3973\n",
      "Epoch 16/20\n",
      "98/98 [==============================] - 101s 1s/step - loss: 1.6854 - accuracy: 0.3700 - val_loss: 1.5823 - val_accuracy: 0.4207\n",
      "Epoch 17/20\n",
      "98/98 [==============================] - 105s 1s/step - loss: 1.6578 - accuracy: 0.3838 - val_loss: 1.5493 - val_accuracy: 0.4311\n",
      "Epoch 18/20\n",
      "98/98 [==============================] - 111s 1s/step - loss: 1.6285 - accuracy: 0.3927 - val_loss: 1.5355 - val_accuracy: 0.4376\n",
      "Epoch 19/20\n",
      "98/98 [==============================] - 101s 1s/step - loss: 1.6031 - accuracy: 0.4060 - val_loss: 1.5085 - val_accuracy: 0.4463\n",
      "Epoch 20/20\n",
      "98/98 [==============================] - 101s 1s/step - loss: 1.5853 - accuracy: 0.4123 - val_loss: 1.4863 - val_accuracy: 0.4531\n",
      "test_loss: 1.4863415956497192, test_accuracy: 0.4530999958515167\n",
      "Numbers of exp: 8, optimizer:Adam, kernel: (3, 3), epochs: 10, pool_size:(2, 2)\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_212 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_313 (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_213 (Conv2D)          (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_314 (Activation)  (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_106 (MaxPoolin (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_155 (Dropout)        (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_214 (Conv2D)          (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_315 (Activation)  (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_215 (Conv2D)          (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_316 (Activation)  (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_107 (MaxPoolin (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_156 (Dropout)        (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_51 (Flatten)         (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_317 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_157 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_318 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "98/98 [==============================] - 73s 731ms/step - loss: 1.8074 - accuracy: 0.3357 - val_loss: 1.5020 - val_accuracy: 0.4546\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 71s 721ms/step - loss: 1.4313 - accuracy: 0.4813 - val_loss: 1.2467 - val_accuracy: 0.5513\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 71s 721ms/step - loss: 1.2724 - accuracy: 0.5434 - val_loss: 1.1291 - val_accuracy: 0.5987\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 71s 726ms/step - loss: 1.1544 - accuracy: 0.5910 - val_loss: 1.0454 - val_accuracy: 0.6292\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 70s 719ms/step - loss: 1.0619 - accuracy: 0.6229 - val_loss: 0.9509 - val_accuracy: 0.6674\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 71s 722ms/step - loss: 0.9797 - accuracy: 0.6567 - val_loss: 0.9322 - val_accuracy: 0.6762\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 71s 721ms/step - loss: 0.9305 - accuracy: 0.6757 - val_loss: 0.8693 - val_accuracy: 0.6934\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 71s 722ms/step - loss: 0.8734 - accuracy: 0.6930 - val_loss: 0.7977 - val_accuracy: 0.7205\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 71s 724ms/step - loss: 0.8272 - accuracy: 0.7098 - val_loss: 0.7834 - val_accuracy: 0.7270\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 71s 721ms/step - loss: 0.7852 - accuracy: 0.7238 - val_loss: 0.7593 - val_accuracy: 0.7374\n",
      "test_loss: 0.7593193650245667, test_accuracy: 0.7373999953269958\n",
      "Numbers of exp: 9, optimizer:Adam, kernel: (3, 3), epochs: 10, pool_size:(3, 3)\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_216 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_319 (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_217 (Conv2D)          (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_320 (Activation)  (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_108 (MaxPoolin (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_158 (Dropout)        (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_218 (Conv2D)          (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_321 (Activation)  (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_219 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_322 (Activation)  (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_109 (MaxPoolin (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_159 (Dropout)        (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_52 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_323 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_160 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_324 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 202,282\n",
      "Trainable params: 202,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "98/98 [==============================] - 51s 517ms/step - loss: 2.0165 - accuracy: 0.2348 - val_loss: 1.6735 - val_accuracy: 0.3771\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 50s 513ms/step - loss: 1.6363 - accuracy: 0.3923 - val_loss: 1.4598 - val_accuracy: 0.4645\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 50s 511ms/step - loss: 1.4920 - accuracy: 0.4515 - val_loss: 1.3550 - val_accuracy: 0.5024\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 50s 509ms/step - loss: 1.4035 - accuracy: 0.4860 - val_loss: 1.2583 - val_accuracy: 0.5430\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 50s 512ms/step - loss: 1.3382 - accuracy: 0.5105 - val_loss: 1.2411 - val_accuracy: 0.5515\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 50s 514ms/step - loss: 1.2716 - accuracy: 0.5396 - val_loss: 1.1441 - val_accuracy: 0.5908\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 50s 512ms/step - loss: 1.2214 - accuracy: 0.5607 - val_loss: 1.1059 - val_accuracy: 0.6054\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 51s 525ms/step - loss: 1.1825 - accuracy: 0.5747 - val_loss: 1.0571 - val_accuracy: 0.6264\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 51s 519ms/step - loss: 1.1426 - accuracy: 0.5930 - val_loss: 1.0310 - val_accuracy: 0.6376\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 50s 514ms/step - loss: 1.1174 - accuracy: 0.6020 - val_loss: 1.0001 - val_accuracy: 0.6442\n",
      "test_loss: 1.0000642538070679, test_accuracy: 0.6442000269889832\n",
      "Numbers of exp: 10, optimizer:Adam, kernel: (3, 3), epochs: 20, pool_size:(2, 2)\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_220 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_325 (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_221 (Conv2D)          (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_326 (Activation)  (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_110 (MaxPoolin (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_161 (Dropout)        (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_222 (Conv2D)          (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_327 (Activation)  (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_223 (Conv2D)          (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_328 (Activation)  (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_111 (MaxPoolin (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_162 (Dropout)        (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_53 (Flatten)         (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_329 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_163 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_330 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "98/98 [==============================] - 69s 704ms/step - loss: 2.1289 - accuracy: 0.2044 - val_loss: 1.9496 - val_accuracy: 0.2905\n",
      "Epoch 2/20\n",
      "98/98 [==============================] - 68s 699ms/step - loss: 1.9436 - accuracy: 0.2773 - val_loss: 1.8336 - val_accuracy: 0.3240\n",
      "Epoch 3/20\n",
      "98/98 [==============================] - 71s 726ms/step - loss: 1.8280 - accuracy: 0.3147 - val_loss: 1.7007 - val_accuracy: 0.3559\n",
      "Epoch 4/20\n",
      "98/98 [==============================] - 69s 708ms/step - loss: 1.7124 - accuracy: 0.3629 - val_loss: 1.5640 - val_accuracy: 0.4240\n",
      "Epoch 5/20\n",
      "98/98 [==============================] - 69s 708ms/step - loss: 1.6068 - accuracy: 0.4037 - val_loss: 1.4695 - val_accuracy: 0.4625\n",
      "Epoch 6/20\n",
      "98/98 [==============================] - 69s 705ms/step - loss: 1.5235 - accuracy: 0.4383 - val_loss: 1.4115 - val_accuracy: 0.4888\n",
      "Epoch 7/20\n",
      "98/98 [==============================] - 69s 705ms/step - loss: 1.4688 - accuracy: 0.4602 - val_loss: 1.3692 - val_accuracy: 0.5057\n",
      "Epoch 8/20\n",
      "98/98 [==============================] - 69s 705ms/step - loss: 1.4256 - accuracy: 0.4791 - val_loss: 1.3353 - val_accuracy: 0.5159\n",
      "Epoch 9/20\n",
      "98/98 [==============================] - 69s 706ms/step - loss: 1.3996 - accuracy: 0.4926 - val_loss: 1.2781 - val_accuracy: 0.5405\n",
      "Epoch 10/20\n",
      "98/98 [==============================] - 71s 720ms/step - loss: 1.3514 - accuracy: 0.5101 - val_loss: 1.2443 - val_accuracy: 0.5565\n",
      "Epoch 11/20\n",
      "98/98 [==============================] - 69s 706ms/step - loss: 1.3239 - accuracy: 0.5194 - val_loss: 1.2518 - val_accuracy: 0.5611\n",
      "Epoch 12/20\n",
      "98/98 [==============================] - 69s 703ms/step - loss: 1.2967 - accuracy: 0.5305 - val_loss: 1.1902 - val_accuracy: 0.5782\n",
      "Epoch 13/20\n",
      "98/98 [==============================] - 69s 704ms/step - loss: 1.2778 - accuracy: 0.5383 - val_loss: 1.1864 - val_accuracy: 0.5769\n",
      "Epoch 14/20\n",
      "98/98 [==============================] - 69s 706ms/step - loss: 1.2483 - accuracy: 0.5502 - val_loss: 1.1419 - val_accuracy: 0.5981\n",
      "Epoch 15/20\n",
      "98/98 [==============================] - 69s 706ms/step - loss: 1.2092 - accuracy: 0.5667 - val_loss: 1.1862 - val_accuracy: 0.5851\n",
      "Epoch 16/20\n",
      "98/98 [==============================] - 69s 702ms/step - loss: 1.1671 - accuracy: 0.5807 - val_loss: 1.0748 - val_accuracy: 0.6190\n",
      "Epoch 17/20\n",
      "98/98 [==============================] - 71s 723ms/step - loss: 1.1411 - accuracy: 0.5925 - val_loss: 1.0347 - val_accuracy: 0.6339\n",
      "Epoch 18/20\n",
      "98/98 [==============================] - 70s 712ms/step - loss: 1.1074 - accuracy: 0.6063 - val_loss: 1.0161 - val_accuracy: 0.6389\n",
      "Epoch 19/20\n",
      "98/98 [==============================] - 70s 712ms/step - loss: 1.0764 - accuracy: 0.6165 - val_loss: 0.9812 - val_accuracy: 0.6552\n",
      "Epoch 20/20\n",
      "98/98 [==============================] - 70s 712ms/step - loss: 1.0465 - accuracy: 0.6279 - val_loss: 0.9794 - val_accuracy: 0.6515\n",
      "test_loss: 0.9794492125511169, test_accuracy: 0.6514999866485596\n",
      "Numbers of exp: 11, optimizer:Adam, kernel: (3, 3), epochs: 20, pool_size:(3, 3)\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_224 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_331 (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_225 (Conv2D)          (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_332 (Activation)  (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_112 (MaxPoolin (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_164 (Dropout)        (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_226 (Conv2D)          (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_333 (Activation)  (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_227 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_334 (Activation)  (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_113 (MaxPoolin (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_165 (Dropout)        (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_54 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_335 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_166 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_336 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 202,282\n",
      "Trainable params: 202,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "98/98 [==============================] - 51s 519ms/step - loss: 1.9788 - accuracy: 0.2538 - val_loss: 1.6455 - val_accuracy: 0.3861\n",
      "Epoch 2/20\n",
      "98/98 [==============================] - 50s 515ms/step - loss: 1.6295 - accuracy: 0.3919 - val_loss: 1.4951 - val_accuracy: 0.4553\n",
      "Epoch 3/20\n",
      "98/98 [==============================] - 50s 513ms/step - loss: 1.4858 - accuracy: 0.4493 - val_loss: 1.3271 - val_accuracy: 0.5230\n",
      "Epoch 4/20\n",
      "98/98 [==============================] - 51s 518ms/step - loss: 1.4003 - accuracy: 0.4905 - val_loss: 1.2431 - val_accuracy: 0.5560\n",
      "Epoch 5/20\n",
      "98/98 [==============================] - 50s 515ms/step - loss: 1.3257 - accuracy: 0.5187 - val_loss: 1.2006 - val_accuracy: 0.5758\n",
      "Epoch 6/20\n",
      "98/98 [==============================] - 51s 518ms/step - loss: 1.2766 - accuracy: 0.5401 - val_loss: 1.1289 - val_accuracy: 0.6045\n",
      "Epoch 7/20\n",
      "98/98 [==============================] - 51s 517ms/step - loss: 1.2272 - accuracy: 0.5618 - val_loss: 1.1346 - val_accuracy: 0.5993\n",
      "Epoch 8/20\n",
      "98/98 [==============================] - 52s 530ms/step - loss: 1.2010 - accuracy: 0.5730 - val_loss: 1.0769 - val_accuracy: 0.6188\n",
      "Epoch 9/20\n",
      "98/98 [==============================] - 51s 517ms/step - loss: 1.1669 - accuracy: 0.5844 - val_loss: 1.0536 - val_accuracy: 0.6284\n",
      "Epoch 10/20\n",
      "98/98 [==============================] - 51s 516ms/step - loss: 1.1467 - accuracy: 0.5898 - val_loss: 1.0361 - val_accuracy: 0.6317\n",
      "Epoch 11/20\n",
      "98/98 [==============================] - 51s 516ms/step - loss: 1.1206 - accuracy: 0.6029 - val_loss: 0.9994 - val_accuracy: 0.6474\n",
      "Epoch 12/20\n",
      "98/98 [==============================] - 50s 514ms/step - loss: 1.1029 - accuracy: 0.6075 - val_loss: 1.0191 - val_accuracy: 0.6402\n",
      "Epoch 13/20\n",
      "98/98 [==============================] - 50s 514ms/step - loss: 1.0862 - accuracy: 0.6138 - val_loss: 0.9821 - val_accuracy: 0.6534\n",
      "Epoch 14/20\n",
      "98/98 [==============================] - 51s 517ms/step - loss: 1.0697 - accuracy: 0.6235 - val_loss: 0.9578 - val_accuracy: 0.6602\n",
      "Epoch 15/20\n",
      "98/98 [==============================] - 51s 518ms/step - loss: 1.0473 - accuracy: 0.6266 - val_loss: 0.9452 - val_accuracy: 0.6660\n",
      "Epoch 16/20\n",
      "98/98 [==============================] - 50s 514ms/step - loss: 1.0468 - accuracy: 0.6285 - val_loss: 0.9571 - val_accuracy: 0.6635\n",
      "Epoch 17/20\n",
      "98/98 [==============================] - 51s 516ms/step - loss: 1.0341 - accuracy: 0.6345 - val_loss: 0.9272 - val_accuracy: 0.6747\n",
      "Epoch 18/20\n",
      "98/98 [==============================] - 51s 520ms/step - loss: 1.0167 - accuracy: 0.6409 - val_loss: 0.9436 - val_accuracy: 0.6671\n",
      "Epoch 19/20\n",
      "98/98 [==============================] - 51s 519ms/step - loss: 1.0105 - accuracy: 0.6439 - val_loss: 0.9123 - val_accuracy: 0.6781\n",
      "Epoch 20/20\n",
      "98/98 [==============================] - 51s 519ms/step - loss: 0.9940 - accuracy: 0.6486 - val_loss: 0.8942 - val_accuracy: 0.6808\n",
      "test_loss: 0.8941872119903564, test_accuracy: 0.6808000206947327\n",
      "Numbers of exp: 12, optimizer:Adam, kernel: (5, 5), epochs: 10, pool_size:(2, 2)\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_228 (Conv2D)          (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation_337 (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_229 (Conv2D)          (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_338 (Activation)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_114 (MaxPoolin (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_167 (Dropout)        (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_230 (Conv2D)          (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_339 (Activation)  (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_231 (Conv2D)          (None, 10, 10, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_340 (Activation)  (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_115 (MaxPoolin (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_168 (Dropout)        (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_55 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "activation_341 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_169 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_342 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,006,634\n",
      "Trainable params: 1,006,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "98/98 [==============================] - 133s 1s/step - loss: 2.3067 - accuracy: 0.1022 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 132s 1s/step - loss: 2.3029 - accuracy: 0.0996 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 131s 1s/step - loss: 2.3028 - accuracy: 0.0973 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 131s 1s/step - loss: 2.3028 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 131s 1s/step - loss: 2.3027 - accuracy: 0.0967 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 131s 1s/step - loss: 2.3027 - accuracy: 0.0985 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 132s 1s/step - loss: 2.3027 - accuracy: 0.0967 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 131s 1s/step - loss: 2.3027 - accuracy: 0.1002 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 131s 1s/step - loss: 2.3027 - accuracy: 0.0976 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 131s 1s/step - loss: 2.3027 - accuracy: 0.0971 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "test_loss: 2.3025877475738525, test_accuracy: 0.10000000149011612\n",
      "Numbers of exp: 13, optimizer:Adam, kernel: (5, 5), epochs: 10, pool_size:(3, 3)\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_232 (Conv2D)          (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation_343 (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_233 (Conv2D)          (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_344 (Activation)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_116 (MaxPoolin (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_170 (Dropout)        (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_234 (Conv2D)          (None, 9, 9, 64)          51264     \n",
      "_________________________________________________________________\n",
      "activation_345 (Activation)  (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_235 (Conv2D)          (None, 5, 5, 64)          102464    \n",
      "_________________________________________________________________\n",
      "activation_346 (Activation)  (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_117 (MaxPoolin (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_171 (Dropout)        (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_56 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "activation_347 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_172 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_348 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 220,202\n",
      "Trainable params: 220,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "98/98 [==============================] - 103s 1s/step - loss: 2.1684 - accuracy: 0.1728 - val_loss: 1.9914 - val_accuracy: 0.2467\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 100s 1s/step - loss: 1.9102 - accuracy: 0.2675 - val_loss: 1.7554 - val_accuracy: 0.3449\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 100s 1s/step - loss: 1.7780 - accuracy: 0.3299 - val_loss: 1.6472 - val_accuracy: 0.3935\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 101s 1s/step - loss: 1.6871 - accuracy: 0.3661 - val_loss: 1.5732 - val_accuracy: 0.4165\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 108s 1s/step - loss: 1.6224 - accuracy: 0.3960 - val_loss: 1.5132 - val_accuracy: 0.4405\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 108s 1s/step - loss: 1.5874 - accuracy: 0.4100 - val_loss: 1.5409 - val_accuracy: 0.4400\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 108s 1s/step - loss: 1.5611 - accuracy: 0.4235 - val_loss: 1.4674 - val_accuracy: 0.4616\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 108s 1s/step - loss: 1.5201 - accuracy: 0.4388 - val_loss: 1.4086 - val_accuracy: 0.4795\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 108s 1s/step - loss: 1.4904 - accuracy: 0.4532 - val_loss: 1.4111 - val_accuracy: 0.4895\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 109s 1s/step - loss: 1.4679 - accuracy: 0.4614 - val_loss: 1.3669 - val_accuracy: 0.5027\n",
      "test_loss: 1.3668501377105713, test_accuracy: 0.5026999711990356\n",
      "Numbers of exp: 14, optimizer:Adam, kernel: (5, 5), epochs: 20, pool_size:(2, 2)\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_236 (Conv2D)          (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation_349 (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_237 (Conv2D)          (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_350 (Activation)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_118 (MaxPoolin (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_173 (Dropout)        (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_238 (Conv2D)          (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_351 (Activation)  (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_239 (Conv2D)          (None, 10, 10, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_352 (Activation)  (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_119 (MaxPoolin (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_174 (Dropout)        (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_57 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "activation_353 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_175 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_354 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,006,634\n",
      "Trainable params: 1,006,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "98/98 [==============================] - 143s 1s/step - loss: 2.1712 - accuracy: 0.1876 - val_loss: 1.9130 - val_accuracy: 0.3003\n",
      "Epoch 2/20\n",
      "98/98 [==============================] - 136s 1s/step - loss: 1.8935 - accuracy: 0.3019 - val_loss: 1.8159 - val_accuracy: 0.3312\n",
      "Epoch 3/20\n",
      "98/98 [==============================] - 135s 1s/step - loss: 1.7805 - accuracy: 0.3421 - val_loss: 1.6570 - val_accuracy: 0.3930\n",
      "Epoch 4/20\n",
      "98/98 [==============================] - 134s 1s/step - loss: 1.6890 - accuracy: 0.3781 - val_loss: 1.6046 - val_accuracy: 0.4138\n",
      "Epoch 5/20\n",
      "98/98 [==============================] - 136s 1s/step - loss: 1.6364 - accuracy: 0.4002 - val_loss: 1.5194 - val_accuracy: 0.4464\n",
      "Epoch 6/20\n",
      "98/98 [==============================] - 134s 1s/step - loss: 1.5715 - accuracy: 0.4234 - val_loss: 1.4938 - val_accuracy: 0.4560\n",
      "Epoch 7/20\n",
      "98/98 [==============================] - 134s 1s/step - loss: 1.5386 - accuracy: 0.4387 - val_loss: 1.4366 - val_accuracy: 0.4813\n",
      "Epoch 8/20\n",
      "98/98 [==============================] - 134s 1s/step - loss: 1.4883 - accuracy: 0.4572 - val_loss: 1.4098 - val_accuracy: 0.4948\n",
      "Epoch 9/20\n",
      "98/98 [==============================] - 135s 1s/step - loss: 1.4582 - accuracy: 0.4692 - val_loss: 1.3713 - val_accuracy: 0.5021\n",
      "Epoch 10/20\n",
      "98/98 [==============================] - 134s 1s/step - loss: 1.4244 - accuracy: 0.4830 - val_loss: 1.3314 - val_accuracy: 0.5234\n",
      "Epoch 11/20\n",
      "98/98 [==============================] - 135s 1s/step - loss: 1.3910 - accuracy: 0.4948 - val_loss: 1.2945 - val_accuracy: 0.5377\n",
      "Epoch 12/20\n",
      "98/98 [==============================] - 134s 1s/step - loss: 1.3652 - accuracy: 0.5051 - val_loss: 1.2736 - val_accuracy: 0.5441\n",
      "Epoch 13/20\n",
      "98/98 [==============================] - 134s 1s/step - loss: 1.3456 - accuracy: 0.5143 - val_loss: 1.2519 - val_accuracy: 0.5484\n",
      "Epoch 14/20\n",
      "98/98 [==============================] - 134s 1s/step - loss: 1.3143 - accuracy: 0.5264 - val_loss: 1.2119 - val_accuracy: 0.5636\n",
      "Epoch 15/20\n",
      "98/98 [==============================] - 134s 1s/step - loss: 1.2955 - accuracy: 0.5339 - val_loss: 1.1942 - val_accuracy: 0.5744\n",
      "Epoch 16/20\n",
      "98/98 [==============================] - 135s 1s/step - loss: 1.2687 - accuracy: 0.5422 - val_loss: 1.1826 - val_accuracy: 0.5762\n",
      "Epoch 17/20\n",
      "98/98 [==============================] - 134s 1s/step - loss: 1.2481 - accuracy: 0.5527 - val_loss: 1.1712 - val_accuracy: 0.5825\n",
      "Epoch 18/20\n",
      "98/98 [==============================] - 134s 1s/step - loss: 1.2232 - accuracy: 0.5594 - val_loss: 1.1342 - val_accuracy: 0.5945\n",
      "Epoch 19/20\n",
      "98/98 [==============================] - 135s 1s/step - loss: 1.2084 - accuracy: 0.5674 - val_loss: 1.1114 - val_accuracy: 0.6060\n",
      "Epoch 20/20\n",
      "98/98 [==============================] - 137s 1s/step - loss: 1.1782 - accuracy: 0.5771 - val_loss: 1.1007 - val_accuracy: 0.6086\n",
      "test_loss: 1.1006813049316406, test_accuracy: 0.6086000204086304\n",
      "Numbers of exp: 15, optimizer:Adam, kernel: (5, 5), epochs: 20, pool_size:(3, 3)\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_240 (Conv2D)          (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation_355 (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_241 (Conv2D)          (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_356 (Activation)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_120 (MaxPoolin (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_176 (Dropout)        (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_242 (Conv2D)          (None, 9, 9, 64)          51264     \n",
      "_________________________________________________________________\n",
      "activation_357 (Activation)  (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_243 (Conv2D)          (None, 5, 5, 64)          102464    \n",
      "_________________________________________________________________\n",
      "activation_358 (Activation)  (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_121 (MaxPoolin (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_177 (Dropout)        (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_58 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "activation_359 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_178 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_360 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 220,202\n",
      "Trainable params: 220,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "98/98 [==============================] - 101s 1s/step - loss: 2.1737 - accuracy: 0.1812 - val_loss: 1.9162 - val_accuracy: 0.2870\n",
      "Epoch 2/20\n",
      "98/98 [==============================] - 100s 1s/step - loss: 1.9137 - accuracy: 0.2918 - val_loss: 1.7822 - val_accuracy: 0.3504\n",
      "Epoch 3/20\n",
      "98/98 [==============================] - 103s 1s/step - loss: 1.8340 - accuracy: 0.3246 - val_loss: 1.7180 - val_accuracy: 0.3739\n",
      "Epoch 4/20\n",
      "98/98 [==============================] - 102s 1s/step - loss: 1.7797 - accuracy: 0.3441 - val_loss: 1.6691 - val_accuracy: 0.3943\n",
      "Epoch 5/20\n",
      "98/98 [==============================] - 100s 1s/step - loss: 1.7173 - accuracy: 0.3754 - val_loss: 1.6451 - val_accuracy: 0.4060\n",
      "Epoch 6/20\n",
      "98/98 [==============================] - 102s 1s/step - loss: 1.6777 - accuracy: 0.3889 - val_loss: 1.5918 - val_accuracy: 0.4248\n",
      "Epoch 7/20\n",
      "98/98 [==============================] - 100s 1s/step - loss: 1.6406 - accuracy: 0.4035 - val_loss: 1.5436 - val_accuracy: 0.4483\n",
      "Epoch 8/20\n",
      "98/98 [==============================] - 100s 1s/step - loss: 1.6159 - accuracy: 0.4151 - val_loss: 1.5264 - val_accuracy: 0.4539\n",
      "Epoch 9/20\n",
      "98/98 [==============================] - 101s 1s/step - loss: 1.5905 - accuracy: 0.4254 - val_loss: 1.5475 - val_accuracy: 0.4435\n",
      "Epoch 10/20\n",
      "98/98 [==============================] - 100s 1s/step - loss: 1.5704 - accuracy: 0.4317 - val_loss: 1.5256 - val_accuracy: 0.4528\n",
      "Epoch 11/20\n",
      "98/98 [==============================] - 100s 1s/step - loss: 1.5564 - accuracy: 0.4372 - val_loss: 1.4621 - val_accuracy: 0.4763\n",
      "Epoch 12/20\n",
      "98/98 [==============================] - 100s 1s/step - loss: 1.5436 - accuracy: 0.4414 - val_loss: 1.4732 - val_accuracy: 0.4693\n",
      "Epoch 13/20\n",
      "98/98 [==============================] - 101s 1s/step - loss: 1.5303 - accuracy: 0.4442 - val_loss: 1.4584 - val_accuracy: 0.4788\n",
      "Epoch 14/20\n",
      "98/98 [==============================] - 102s 1s/step - loss: 1.5154 - accuracy: 0.4519 - val_loss: 1.4267 - val_accuracy: 0.4913\n",
      "Epoch 15/20\n",
      "98/98 [==============================] - 102s 1s/step - loss: 1.5081 - accuracy: 0.4526 - val_loss: 1.4859 - val_accuracy: 0.4631\n",
      "Epoch 16/20\n",
      "98/98 [==============================] - 100s 1s/step - loss: 1.4960 - accuracy: 0.4604 - val_loss: 1.4409 - val_accuracy: 0.4776\n",
      "Epoch 17/20\n",
      "98/98 [==============================] - 100s 1s/step - loss: 1.4814 - accuracy: 0.4633 - val_loss: 1.4153 - val_accuracy: 0.4866\n",
      "Epoch 18/20\n",
      "98/98 [==============================] - 101s 1s/step - loss: 1.4719 - accuracy: 0.4674 - val_loss: 1.3936 - val_accuracy: 0.4979\n",
      "Epoch 19/20\n",
      "98/98 [==============================] - 100s 1s/step - loss: 1.4544 - accuracy: 0.4745 - val_loss: 1.3949 - val_accuracy: 0.4992\n",
      "Epoch 20/20\n",
      "98/98 [==============================] - 101s 1s/step - loss: 1.4496 - accuracy: 0.4763 - val_loss: 1.3844 - val_accuracy: 0.5004\n",
      "test_loss: 1.384432077407837, test_accuracy: 0.5004000067710876\n",
      "Numbers of exp: 16, optimizer:RMSprop, kernel: (3, 3), epochs: 10, pool_size:(2, 2)\n",
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_244 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_361 (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_245 (Conv2D)          (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_362 (Activation)  (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_122 (MaxPoolin (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_179 (Dropout)        (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_246 (Conv2D)          (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_363 (Activation)  (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_247 (Conv2D)          (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_364 (Activation)  (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_123 (MaxPoolin (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_180 (Dropout)        (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_59 (Flatten)         (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_365 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_181 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_366 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "98/98 [==============================] - 72s 733ms/step - loss: 2.0147 - accuracy: 0.2695 - val_loss: 1.6387 - val_accuracy: 0.4278\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 71s 726ms/step - loss: 1.6525 - accuracy: 0.4090 - val_loss: 1.4378 - val_accuracy: 0.4880\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 71s 729ms/step - loss: 1.4630 - accuracy: 0.4814 - val_loss: 1.2480 - val_accuracy: 0.5525\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 71s 727ms/step - loss: 1.3272 - accuracy: 0.5322 - val_loss: 1.2920 - val_accuracy: 0.5414\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 71s 729ms/step - loss: 1.2272 - accuracy: 0.5652 - val_loss: 1.1155 - val_accuracy: 0.6038\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 71s 728ms/step - loss: 1.1390 - accuracy: 0.5994 - val_loss: 1.0060 - val_accuracy: 0.6436\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 71s 728ms/step - loss: 1.0684 - accuracy: 0.6276 - val_loss: 1.1148 - val_accuracy: 0.6180\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 71s 728ms/step - loss: 0.9996 - accuracy: 0.6509 - val_loss: 0.9565 - val_accuracy: 0.6640\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 71s 728ms/step - loss: 0.9558 - accuracy: 0.6664 - val_loss: 0.9275 - val_accuracy: 0.6766\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 72s 731ms/step - loss: 0.9004 - accuracy: 0.6858 - val_loss: 0.8985 - val_accuracy: 0.6892\n",
      "test_loss: 0.8985453248023987, test_accuracy: 0.6891999840736389\n",
      "Numbers of exp: 17, optimizer:RMSprop, kernel: (3, 3), epochs: 10, pool_size:(3, 3)\n",
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_248 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_367 (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_249 (Conv2D)          (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_368 (Activation)  (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_124 (MaxPoolin (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_182 (Dropout)        (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_250 (Conv2D)          (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_369 (Activation)  (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_251 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_370 (Activation)  (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_125 (MaxPoolin (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_183 (Dropout)        (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_60 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_371 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_184 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_372 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 202,282\n",
      "Trainable params: 202,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "98/98 [==============================] - 52s 522ms/step - loss: 2.1096 - accuracy: 0.2187 - val_loss: 1.8848 - val_accuracy: 0.3359\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 51s 522ms/step - loss: 1.8466 - accuracy: 0.3300 - val_loss: 1.5973 - val_accuracy: 0.4338\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 51s 520ms/step - loss: 1.6668 - accuracy: 0.3959 - val_loss: 1.4544 - val_accuracy: 0.4790\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 51s 521ms/step - loss: 1.5418 - accuracy: 0.4441 - val_loss: 1.5120 - val_accuracy: 0.4620\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 51s 517ms/step - loss: 1.4587 - accuracy: 0.4782 - val_loss: 1.3492 - val_accuracy: 0.5089\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 51s 517ms/step - loss: 1.3840 - accuracy: 0.5062 - val_loss: 1.2515 - val_accuracy: 0.5615\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 51s 519ms/step - loss: 1.3318 - accuracy: 0.5274 - val_loss: 1.2807 - val_accuracy: 0.5514\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 51s 519ms/step - loss: 1.2731 - accuracy: 0.5475 - val_loss: 1.1355 - val_accuracy: 0.5981\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 51s 521ms/step - loss: 1.2298 - accuracy: 0.5662 - val_loss: 1.1960 - val_accuracy: 0.5814\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 51s 520ms/step - loss: 1.1879 - accuracy: 0.5819 - val_loss: 1.1247 - val_accuracy: 0.6122\n",
      "test_loss: 1.1247107982635498, test_accuracy: 0.6122000217437744\n",
      "Numbers of exp: 18, optimizer:RMSprop, kernel: (3, 3), epochs: 20, pool_size:(2, 2)\n",
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_252 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_373 (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_253 (Conv2D)          (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_374 (Activation)  (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_126 (MaxPoolin (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_185 (Dropout)        (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_254 (Conv2D)          (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_375 (Activation)  (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_255 (Conv2D)          (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_376 (Activation)  (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_127 (MaxPoolin (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_186 (Dropout)        (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_61 (Flatten)         (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_377 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_187 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_378 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "98/98 [==============================] - 72s 731ms/step - loss: 2.0759 - accuracy: 0.2464 - val_loss: 1.8890 - val_accuracy: 0.3338\n",
      "Epoch 2/20\n",
      "98/98 [==============================] - 71s 722ms/step - loss: 1.7004 - accuracy: 0.3899 - val_loss: 1.7634 - val_accuracy: 0.3685\n",
      "Epoch 3/20\n",
      "98/98 [==============================] - 73s 746ms/step - loss: 1.5061 - accuracy: 0.4619 - val_loss: 1.3842 - val_accuracy: 0.5026\n",
      "Epoch 4/20\n",
      "98/98 [==============================] - 71s 725ms/step - loss: 1.3813 - accuracy: 0.5129 - val_loss: 1.3110 - val_accuracy: 0.5275\n",
      "Epoch 5/20\n",
      "98/98 [==============================] - 71s 721ms/step - loss: 1.2844 - accuracy: 0.5499 - val_loss: 1.0968 - val_accuracy: 0.6173\n",
      "Epoch 6/20\n",
      "98/98 [==============================] - 71s 721ms/step - loss: 1.1854 - accuracy: 0.5853 - val_loss: 1.0894 - val_accuracy: 0.6177\n",
      "Epoch 7/20\n",
      "98/98 [==============================] - 71s 720ms/step - loss: 1.1189 - accuracy: 0.6071 - val_loss: 1.0162 - val_accuracy: 0.6491\n",
      "Epoch 8/20\n",
      "98/98 [==============================] - 71s 720ms/step - loss: 1.0514 - accuracy: 0.6333 - val_loss: 0.9697 - val_accuracy: 0.6547\n",
      "Epoch 9/20\n",
      "98/98 [==============================] - 70s 720ms/step - loss: 0.9900 - accuracy: 0.6549 - val_loss: 0.9425 - val_accuracy: 0.6671\n",
      "Epoch 10/20\n",
      "98/98 [==============================] - 71s 721ms/step - loss: 0.9414 - accuracy: 0.6723 - val_loss: 0.8896 - val_accuracy: 0.6958\n",
      "Epoch 11/20\n",
      "98/98 [==============================] - 71s 721ms/step - loss: 0.8867 - accuracy: 0.6898 - val_loss: 0.8307 - val_accuracy: 0.7147\n",
      "Epoch 12/20\n",
      "98/98 [==============================] - 70s 719ms/step - loss: 0.8487 - accuracy: 0.7036 - val_loss: 0.9142 - val_accuracy: 0.6909\n",
      "Epoch 13/20\n",
      "98/98 [==============================] - 70s 719ms/step - loss: 0.8075 - accuracy: 0.7184 - val_loss: 0.7870 - val_accuracy: 0.7285\n",
      "Epoch 14/20\n",
      "98/98 [==============================] - 71s 721ms/step - loss: 0.7794 - accuracy: 0.7289 - val_loss: 0.8049 - val_accuracy: 0.7256\n",
      "Epoch 15/20\n",
      "98/98 [==============================] - 70s 718ms/step - loss: 0.7366 - accuracy: 0.7416 - val_loss: 0.8237 - val_accuracy: 0.7143\n",
      "Epoch 16/20\n",
      "98/98 [==============================] - 70s 719ms/step - loss: 0.7067 - accuracy: 0.7542 - val_loss: 0.7339 - val_accuracy: 0.7448\n",
      "Epoch 17/20\n",
      "98/98 [==============================] - 71s 720ms/step - loss: 0.6751 - accuracy: 0.7633 - val_loss: 0.7266 - val_accuracy: 0.7502\n",
      "Epoch 18/20\n",
      "98/98 [==============================] - 70s 719ms/step - loss: 0.6507 - accuracy: 0.7727 - val_loss: 0.7129 - val_accuracy: 0.7559\n",
      "Epoch 19/20\n",
      "98/98 [==============================] - 70s 717ms/step - loss: 0.6275 - accuracy: 0.7816 - val_loss: 0.7389 - val_accuracy: 0.7496\n",
      "Epoch 20/20\n",
      "98/98 [==============================] - 70s 718ms/step - loss: 0.6072 - accuracy: 0.7860 - val_loss: 0.7612 - val_accuracy: 0.7395\n",
      "test_loss: 0.7611613273620605, test_accuracy: 0.7394999861717224\n",
      "Numbers of exp: 19, optimizer:RMSprop, kernel: (3, 3), epochs: 20, pool_size:(3, 3)\n",
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_256 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_379 (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_257 (Conv2D)          (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_380 (Activation)  (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_128 (MaxPoolin (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_188 (Dropout)        (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_258 (Conv2D)          (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_381 (Activation)  (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_259 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_382 (Activation)  (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_129 (MaxPoolin (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_189 (Dropout)        (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_62 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_383 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_190 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_384 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 202,282\n",
      "Trainable params: 202,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "98/98 [==============================] - 52s 526ms/step - loss: 2.1047 - accuracy: 0.2230 - val_loss: 1.9324 - val_accuracy: 0.2985\n",
      "Epoch 2/20\n",
      "98/98 [==============================] - 51s 525ms/step - loss: 1.8396 - accuracy: 0.3349 - val_loss: 1.9506 - val_accuracy: 0.3081\n",
      "Epoch 3/20\n",
      "98/98 [==============================] - 51s 520ms/step - loss: 1.6850 - accuracy: 0.3900 - val_loss: 1.4878 - val_accuracy: 0.4657\n",
      "Epoch 4/20\n",
      "98/98 [==============================] - 52s 531ms/step - loss: 1.5741 - accuracy: 0.4307 - val_loss: 1.5473 - val_accuracy: 0.4452\n",
      "Epoch 5/20\n",
      "98/98 [==============================] - 51s 523ms/step - loss: 1.4885 - accuracy: 0.4660 - val_loss: 1.3333 - val_accuracy: 0.5217\n",
      "Epoch 6/20\n",
      "98/98 [==============================] - 51s 523ms/step - loss: 1.4100 - accuracy: 0.4918 - val_loss: 1.2716 - val_accuracy: 0.5456\n",
      "Epoch 7/20\n",
      "98/98 [==============================] - 53s 543ms/step - loss: 1.3450 - accuracy: 0.5198 - val_loss: 1.3240 - val_accuracy: 0.5237\n",
      "Epoch 8/20\n",
      "98/98 [==============================] - 51s 520ms/step - loss: 1.2917 - accuracy: 0.5377 - val_loss: 1.1484 - val_accuracy: 0.5896\n",
      "Epoch 9/20\n",
      "98/98 [==============================] - 51s 521ms/step - loss: 1.2446 - accuracy: 0.5595 - val_loss: 1.2568 - val_accuracy: 0.5641\n",
      "Epoch 10/20\n",
      "98/98 [==============================] - 51s 522ms/step - loss: 1.2134 - accuracy: 0.5735 - val_loss: 1.0957 - val_accuracy: 0.6162\n",
      "Epoch 11/20\n",
      "98/98 [==============================] - 51s 523ms/step - loss: 1.1716 - accuracy: 0.5865 - val_loss: 1.0532 - val_accuracy: 0.6301\n",
      "Epoch 12/20\n",
      "98/98 [==============================] - 51s 518ms/step - loss: 1.1301 - accuracy: 0.6022 - val_loss: 1.0755 - val_accuracy: 0.6274\n",
      "Epoch 13/20\n",
      "98/98 [==============================] - 52s 536ms/step - loss: 1.1010 - accuracy: 0.6119 - val_loss: 1.0926 - val_accuracy: 0.6152\n",
      "Epoch 14/20\n",
      "98/98 [==============================] - 52s 529ms/step - loss: 1.0693 - accuracy: 0.6237 - val_loss: 0.9949 - val_accuracy: 0.6513\n",
      "Epoch 15/20\n",
      "98/98 [==============================] - 51s 522ms/step - loss: 1.0537 - accuracy: 0.6301 - val_loss: 0.9751 - val_accuracy: 0.6597\n",
      "Epoch 16/20\n",
      "98/98 [==============================] - 51s 521ms/step - loss: 1.0142 - accuracy: 0.6450 - val_loss: 0.9189 - val_accuracy: 0.6767\n",
      "Epoch 17/20\n",
      "98/98 [==============================] - 51s 520ms/step - loss: 1.0009 - accuracy: 0.6508 - val_loss: 1.0308 - val_accuracy: 0.6370\n",
      "Epoch 18/20\n",
      "98/98 [==============================] - 51s 520ms/step - loss: 0.9777 - accuracy: 0.6583 - val_loss: 0.8828 - val_accuracy: 0.6908\n",
      "Epoch 19/20\n",
      "98/98 [==============================] - 52s 527ms/step - loss: 0.9498 - accuracy: 0.6660 - val_loss: 0.9017 - val_accuracy: 0.6818\n",
      "Epoch 20/20\n",
      "98/98 [==============================] - 51s 522ms/step - loss: 0.9351 - accuracy: 0.6715 - val_loss: 0.8855 - val_accuracy: 0.6870\n",
      "test_loss: 0.8854889869689941, test_accuracy: 0.6869999766349792\n",
      "Numbers of exp: 20, optimizer:RMSprop, kernel: (5, 5), epochs: 10, pool_size:(2, 2)\n",
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_260 (Conv2D)          (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation_385 (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_261 (Conv2D)          (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_386 (Activation)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_130 (MaxPoolin (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_191 (Dropout)        (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_262 (Conv2D)          (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_387 (Activation)  (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_263 (Conv2D)          (None, 10, 10, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_388 (Activation)  (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_131 (MaxPoolin (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_192 (Dropout)        (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_63 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "activation_389 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_193 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_390 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,006,634\n",
      "Trainable params: 1,006,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "98/98 [==============================] - 136s 1s/step - loss: 2.2213 - accuracy: 0.1874 - val_loss: 1.9294 - val_accuracy: 0.2968\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 135s 1s/step - loss: 1.9179 - accuracy: 0.3124 - val_loss: 1.5651 - val_accuracy: 0.4326\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 135s 1s/step - loss: 1.6324 - accuracy: 0.4182 - val_loss: 1.5471 - val_accuracy: 0.4492\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 136s 1s/step - loss: 1.4700 - accuracy: 0.4766 - val_loss: 1.3739 - val_accuracy: 0.5115\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 135s 1s/step - loss: 1.3389 - accuracy: 0.5268 - val_loss: 1.1444 - val_accuracy: 0.5903\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 135s 1s/step - loss: 1.2425 - accuracy: 0.5643 - val_loss: 1.0434 - val_accuracy: 0.6322\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 135s 1s/step - loss: 1.1445 - accuracy: 0.5985 - val_loss: 1.0612 - val_accuracy: 0.6270\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 136s 1s/step - loss: 1.0618 - accuracy: 0.6282 - val_loss: 1.2903 - val_accuracy: 0.5548\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 136s 1s/step - loss: 0.9975 - accuracy: 0.6526 - val_loss: 0.9158 - val_accuracy: 0.6859\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 137s 1s/step - loss: 0.9343 - accuracy: 0.6748 - val_loss: 0.9536 - val_accuracy: 0.6749\n",
      "test_loss: 0.9535642862319946, test_accuracy: 0.6748999953269958\n",
      "Numbers of exp: 21, optimizer:RMSprop, kernel: (5, 5), epochs: 10, pool_size:(3, 3)\n",
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_264 (Conv2D)          (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation_391 (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_265 (Conv2D)          (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_392 (Activation)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_132 (MaxPoolin (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_194 (Dropout)        (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_266 (Conv2D)          (None, 9, 9, 64)          51264     \n",
      "_________________________________________________________________\n",
      "activation_393 (Activation)  (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_267 (Conv2D)          (None, 5, 5, 64)          102464    \n",
      "_________________________________________________________________\n",
      "activation_394 (Activation)  (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_133 (MaxPoolin (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_195 (Dropout)        (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_64 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "activation_395 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_196 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_396 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 220,202\n",
      "Trainable params: 220,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "98/98 [==============================] - 102s 1s/step - loss: 2.2144 - accuracy: 0.1733 - val_loss: 1.9708 - val_accuracy: 0.3001\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 101s 1s/step - loss: 1.9315 - accuracy: 0.2901 - val_loss: 1.8109 - val_accuracy: 0.3531\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 101s 1s/step - loss: 1.7313 - accuracy: 0.3692 - val_loss: 1.4834 - val_accuracy: 0.4700\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 102s 1s/step - loss: 1.5823 - accuracy: 0.4294 - val_loss: 1.3874 - val_accuracy: 0.4978\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 101s 1s/step - loss: 1.4697 - accuracy: 0.4751 - val_loss: 1.3561 - val_accuracy: 0.5131\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 102s 1s/step - loss: 1.3865 - accuracy: 0.5074 - val_loss: 1.2462 - val_accuracy: 0.5614\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 102s 1s/step - loss: 1.3105 - accuracy: 0.5366 - val_loss: 1.2265 - val_accuracy: 0.5667\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 103s 1s/step - loss: 1.2416 - accuracy: 0.5641 - val_loss: 1.1587 - val_accuracy: 0.5935\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 101s 1s/step - loss: 1.1754 - accuracy: 0.5871 - val_loss: 1.1617 - val_accuracy: 0.6017\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 102s 1s/step - loss: 1.1275 - accuracy: 0.6072 - val_loss: 1.0041 - val_accuracy: 0.6508\n",
      "test_loss: 1.0040782690048218, test_accuracy: 0.6507999897003174\n",
      "Numbers of exp: 22, optimizer:RMSprop, kernel: (5, 5), epochs: 20, pool_size:(2, 2)\n",
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_268 (Conv2D)          (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation_397 (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_269 (Conv2D)          (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_398 (Activation)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_134 (MaxPoolin (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_197 (Dropout)        (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_270 (Conv2D)          (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_399 (Activation)  (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_271 (Conv2D)          (None, 10, 10, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_400 (Activation)  (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_135 (MaxPoolin (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_198 (Dropout)        (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_65 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "activation_401 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_199 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_402 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,006,634\n",
      "Trainable params: 1,006,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "98/98 [==============================] - 136s 1s/step - loss: 2.2375 - accuracy: 0.1729 - val_loss: 1.9714 - val_accuracy: 0.3089\n",
      "Epoch 2/20\n",
      "98/98 [==============================] - 135s 1s/step - loss: 1.8631 - accuracy: 0.3305 - val_loss: 1.6768 - val_accuracy: 0.3996\n",
      "Epoch 3/20\n",
      "98/98 [==============================] - 136s 1s/step - loss: 1.6549 - accuracy: 0.4070 - val_loss: 1.4585 - val_accuracy: 0.4747\n",
      "Epoch 4/20\n",
      "98/98 [==============================] - 136s 1s/step - loss: 1.5217 - accuracy: 0.4576 - val_loss: 1.4383 - val_accuracy: 0.4882\n",
      "Epoch 5/20\n",
      "98/98 [==============================] - 137s 1s/step - loss: 1.3896 - accuracy: 0.5064 - val_loss: 1.2186 - val_accuracy: 0.5669\n",
      "Epoch 6/20\n",
      "98/98 [==============================] - 136s 1s/step - loss: 1.2793 - accuracy: 0.5476 - val_loss: 1.2280 - val_accuracy: 0.5708\n",
      "Epoch 7/20\n",
      "98/98 [==============================] - 138s 1s/step - loss: 1.1890 - accuracy: 0.5828 - val_loss: 1.1970 - val_accuracy: 0.5756\n",
      "Epoch 8/20\n",
      "98/98 [==============================] - 135s 1s/step - loss: 1.1107 - accuracy: 0.6120 - val_loss: 1.1992 - val_accuracy: 0.5864\n",
      "Epoch 9/20\n",
      "98/98 [==============================] - 136s 1s/step - loss: 1.0357 - accuracy: 0.6389 - val_loss: 1.1317 - val_accuracy: 0.6115\n",
      "Epoch 10/20\n",
      "98/98 [==============================] - 138s 1s/step - loss: 0.9783 - accuracy: 0.6595 - val_loss: 0.9285 - val_accuracy: 0.6727\n",
      "Epoch 11/20\n",
      "98/98 [==============================] - 136s 1s/step - loss: 0.9228 - accuracy: 0.6818 - val_loss: 0.8859 - val_accuracy: 0.6889\n",
      "Epoch 12/20\n",
      "98/98 [==============================] - 138s 1s/step - loss: 0.8772 - accuracy: 0.6937 - val_loss: 0.8591 - val_accuracy: 0.7036\n",
      "Epoch 13/20\n",
      "98/98 [==============================] - 136s 1s/step - loss: 0.8439 - accuracy: 0.7074 - val_loss: 0.8667 - val_accuracy: 0.7029\n",
      "Epoch 14/20\n",
      "98/98 [==============================] - 136s 1s/step - loss: 0.7893 - accuracy: 0.7256 - val_loss: 0.8462 - val_accuracy: 0.7118\n",
      "Epoch 15/20\n",
      "98/98 [==============================] - 136s 1s/step - loss: 0.7408 - accuracy: 0.7422 - val_loss: 0.7834 - val_accuracy: 0.7300\n",
      "Epoch 16/20\n",
      "98/98 [==============================] - 135s 1s/step - loss: 0.7219 - accuracy: 0.7508 - val_loss: 0.7380 - val_accuracy: 0.7462\n",
      "Epoch 17/20\n",
      "98/98 [==============================] - 136s 1s/step - loss: 0.6916 - accuracy: 0.7588 - val_loss: 0.7464 - val_accuracy: 0.7466\n",
      "Epoch 18/20\n",
      "98/98 [==============================] - 136s 1s/step - loss: 0.6655 - accuracy: 0.7700 - val_loss: 0.7264 - val_accuracy: 0.7514\n",
      "Epoch 19/20\n",
      "98/98 [==============================] - 136s 1s/step - loss: 0.6293 - accuracy: 0.7811 - val_loss: 0.7433 - val_accuracy: 0.7514\n",
      "Epoch 20/20\n",
      "98/98 [==============================] - 136s 1s/step - loss: 0.6035 - accuracy: 0.7893 - val_loss: 0.8671 - val_accuracy: 0.7185\n",
      "test_loss: 0.8670749068260193, test_accuracy: 0.718500018119812\n",
      "Numbers of exp: 23, optimizer:RMSprop, kernel: (5, 5), epochs: 20, pool_size:(3, 3)\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_272 (Conv2D)          (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation_403 (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_273 (Conv2D)          (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_404 (Activation)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_136 (MaxPoolin (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_200 (Dropout)        (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_274 (Conv2D)          (None, 9, 9, 64)          51264     \n",
      "_________________________________________________________________\n",
      "activation_405 (Activation)  (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_275 (Conv2D)          (None, 5, 5, 64)          102464    \n",
      "_________________________________________________________________\n",
      "activation_406 (Activation)  (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_137 (MaxPoolin (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_201 (Dropout)        (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_66 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "activation_407 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_202 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_408 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 220,202\n",
      "Trainable params: 220,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "98/98 [==============================] - 102s 1s/step - loss: 2.1940 - accuracy: 0.1838 - val_loss: 1.9765 - val_accuracy: 0.3165\n",
      "Epoch 2/20\n",
      "98/98 [==============================] - 102s 1s/step - loss: 1.9060 - accuracy: 0.3088 - val_loss: 1.6470 - val_accuracy: 0.4008\n",
      "Epoch 3/20\n",
      "98/98 [==============================] - 101s 1s/step - loss: 1.6999 - accuracy: 0.3803 - val_loss: 1.5843 - val_accuracy: 0.4277\n",
      "Epoch 4/20\n",
      "98/98 [==============================] - 102s 1s/step - loss: 1.5666 - accuracy: 0.4332 - val_loss: 1.6195 - val_accuracy: 0.4186\n",
      "Epoch 5/20\n",
      "98/98 [==============================] - 102s 1s/step - loss: 1.4595 - accuracy: 0.4756 - val_loss: 1.5901 - val_accuracy: 0.4550\n",
      "Epoch 6/20\n",
      "98/98 [==============================] - 102s 1s/step - loss: 1.3745 - accuracy: 0.5099 - val_loss: 1.2598 - val_accuracy: 0.5450\n",
      "Epoch 7/20\n",
      "98/98 [==============================] - 101s 1s/step - loss: 1.2939 - accuracy: 0.5409 - val_loss: 1.3983 - val_accuracy: 0.5204\n",
      "Epoch 8/20\n",
      "98/98 [==============================] - 102s 1s/step - loss: 1.2330 - accuracy: 0.5630 - val_loss: 1.1279 - val_accuracy: 0.5994\n",
      "Epoch 9/20\n",
      "98/98 [==============================] - 104s 1s/step - loss: 1.1767 - accuracy: 0.5858 - val_loss: 1.0561 - val_accuracy: 0.6293\n",
      "Epoch 10/20\n",
      "98/98 [==============================] - 101s 1s/step - loss: 1.1192 - accuracy: 0.6089 - val_loss: 1.0106 - val_accuracy: 0.6466\n",
      "Epoch 11/20\n",
      "98/98 [==============================] - 102s 1s/step - loss: 1.0696 - accuracy: 0.6281 - val_loss: 1.0707 - val_accuracy: 0.6321\n",
      "Epoch 12/20\n",
      "98/98 [==============================] - 101s 1s/step - loss: 1.0328 - accuracy: 0.6415 - val_loss: 0.9540 - val_accuracy: 0.6668\n",
      "Epoch 13/20\n",
      "98/98 [==============================] - 102s 1s/step - loss: 0.9859 - accuracy: 0.6561 - val_loss: 1.0180 - val_accuracy: 0.6464\n",
      "Epoch 14/20\n",
      "98/98 [==============================] - 105s 1s/step - loss: 0.9556 - accuracy: 0.6697 - val_loss: 0.9298 - val_accuracy: 0.6717\n",
      "Epoch 15/20\n",
      "98/98 [==============================] - 104s 1s/step - loss: 0.9252 - accuracy: 0.6808 - val_loss: 0.9145 - val_accuracy: 0.6874\n",
      "Epoch 16/20\n",
      "98/98 [==============================] - 102s 1s/step - loss: 0.9025 - accuracy: 0.6871 - val_loss: 0.9094 - val_accuracy: 0.6882\n",
      "Epoch 17/20\n",
      "98/98 [==============================] - 102s 1s/step - loss: 0.8705 - accuracy: 0.6994 - val_loss: 0.8587 - val_accuracy: 0.7067\n",
      "Epoch 18/20\n",
      "98/98 [==============================] - 103s 1s/step - loss: 0.8540 - accuracy: 0.7073 - val_loss: 0.8275 - val_accuracy: 0.7169\n",
      "Epoch 19/20\n",
      "98/98 [==============================] - 101s 1s/step - loss: 0.8194 - accuracy: 0.7180 - val_loss: 0.8088 - val_accuracy: 0.7245\n",
      "Epoch 20/20\n",
      "98/98 [==============================] - 103s 1s/step - loss: 0.8063 - accuracy: 0.7211 - val_loss: 0.8548 - val_accuracy: 0.7049\n",
      "test_loss: 0.8547685742378235, test_accuracy: 0.7049000263214111\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = {}\n",
    "for i, (optim, kernel, epochs, pool_size) in enumerate(itertools.product(optimizer_set, kernels, epochs, pool_sizes )):\n",
    "    print(f\"Numbers of exp: {i}, optimizer:{type(optim).__name__}, kernel: {kernel}, epochs: {epochs}, pool_size:{pool_size}\")\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel, padding='same',\n",
    "                     input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, kernel))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, kernel, padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, kernel))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optim,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    test_loss = score[0]\n",
    "    \n",
    "    test_accuracy = score[1]\n",
    "    \n",
    "    # Collect results\n",
    "    print(f\"test_loss: {test_loss}, test_accuracy: {test_accuracy}\")\n",
    "    exp_name_tag = (f\"Numbers of exp: {i}, optimizer:{type(optim).__name__}, kernel: {kernel}, epochs: {epochs}, pool_size:{pool_size}\")\n",
    "    results[exp_name_tag] = {#'train-loss': model.history.history[\"loss\"],\n",
    "                             #'valid-loss': model.history.history[\"val_loss\"],\n",
    "                             #'train-acc': model.history.history[\"accuracy\"],\n",
    "                             #'valid-acc': model.history.history[\"val_accuracy\"],\n",
    "                             'Test loss': test_loss,\n",
    "                             'test accuracy': test_accuracy\n",
    "                            }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Numbers of exp: 0, optimizer:SGD, kernel: (3, 3), epochs: 10, pool_size:(2, 2)': {'Test loss': 1.7792236804962158,\n",
       "  'test accuracy': 0.37880000472068787},\n",
       " 'Numbers of exp: 1, optimizer:SGD, kernel: (3, 3), epochs: 10, pool_size:(3, 3)': {'Test loss': 1.9612817764282227,\n",
       "  'test accuracy': 0.2651999890804291},\n",
       " 'Numbers of exp: 2, optimizer:SGD, kernel: (3, 3), epochs: 20, pool_size:(2, 2)': {'Test loss': 1.417934536933899,\n",
       "  'test accuracy': 0.4846000075340271},\n",
       " 'Numbers of exp: 3, optimizer:SGD, kernel: (3, 3), epochs: 20, pool_size:(3, 3)': {'Test loss': 1.6679441928863525,\n",
       "  'test accuracy': 0.3921000063419342},\n",
       " 'Numbers of exp: 4, optimizer:SGD, kernel: (5, 5), epochs: 10, pool_size:(2, 2)': {'Test loss': 1.534393310546875,\n",
       "  'test accuracy': 0.4415999948978424},\n",
       " 'Numbers of exp: 5, optimizer:SGD, kernel: (5, 5), epochs: 10, pool_size:(3, 3)': {'Test loss': 1.8250279426574707,\n",
       "  'test accuracy': 0.32109999656677246},\n",
       " 'Numbers of exp: 6, optimizer:SGD, kernel: (5, 5), epochs: 20, pool_size:(2, 2)': {'Test loss': 1.315718650817871,\n",
       "  'test accuracy': 0.5228999853134155},\n",
       " 'Numbers of exp: 7, optimizer:SGD, kernel: (5, 5), epochs: 20, pool_size:(3, 3)': {'Test loss': 1.4863415956497192,\n",
       "  'test accuracy': 0.4530999958515167},\n",
       " 'Numbers of exp: 8, optimizer:Adam, kernel: (3, 3), epochs: 10, pool_size:(2, 2)': {'Test loss': 0.7593193650245667,\n",
       "  'test accuracy': 0.7373999953269958},\n",
       " 'Numbers of exp: 9, optimizer:Adam, kernel: (3, 3), epochs: 10, pool_size:(3, 3)': {'Test loss': 1.0000642538070679,\n",
       "  'test accuracy': 0.6442000269889832},\n",
       " 'Numbers of exp: 10, optimizer:Adam, kernel: (3, 3), epochs: 20, pool_size:(2, 2)': {'Test loss': 0.9794492125511169,\n",
       "  'test accuracy': 0.6514999866485596},\n",
       " 'Numbers of exp: 11, optimizer:Adam, kernel: (3, 3), epochs: 20, pool_size:(3, 3)': {'Test loss': 0.8941872119903564,\n",
       "  'test accuracy': 0.6808000206947327},\n",
       " 'Numbers of exp: 12, optimizer:Adam, kernel: (5, 5), epochs: 10, pool_size:(2, 2)': {'Test loss': 2.3025877475738525,\n",
       "  'test accuracy': 0.10000000149011612},\n",
       " 'Numbers of exp: 13, optimizer:Adam, kernel: (5, 5), epochs: 10, pool_size:(3, 3)': {'Test loss': 1.3668501377105713,\n",
       "  'test accuracy': 0.5026999711990356},\n",
       " 'Numbers of exp: 14, optimizer:Adam, kernel: (5, 5), epochs: 20, pool_size:(2, 2)': {'Test loss': 1.1006813049316406,\n",
       "  'test accuracy': 0.6086000204086304},\n",
       " 'Numbers of exp: 15, optimizer:Adam, kernel: (5, 5), epochs: 20, pool_size:(3, 3)': {'Test loss': 1.384432077407837,\n",
       "  'test accuracy': 0.5004000067710876},\n",
       " 'Numbers of exp: 16, optimizer:RMSprop, kernel: (3, 3), epochs: 10, pool_size:(2, 2)': {'Test loss': 0.8985453248023987,\n",
       "  'test accuracy': 0.6891999840736389},\n",
       " 'Numbers of exp: 17, optimizer:RMSprop, kernel: (3, 3), epochs: 10, pool_size:(3, 3)': {'Test loss': 1.1247107982635498,\n",
       "  'test accuracy': 0.6122000217437744},\n",
       " 'Numbers of exp: 18, optimizer:RMSprop, kernel: (3, 3), epochs: 20, pool_size:(2, 2)': {'Test loss': 0.7611613273620605,\n",
       "  'test accuracy': 0.7394999861717224},\n",
       " 'Numbers of exp: 19, optimizer:RMSprop, kernel: (3, 3), epochs: 20, pool_size:(3, 3)': {'Test loss': 0.8854889869689941,\n",
       "  'test accuracy': 0.6869999766349792},\n",
       " 'Numbers of exp: 20, optimizer:RMSprop, kernel: (5, 5), epochs: 10, pool_size:(2, 2)': {'Test loss': 0.9535642862319946,\n",
       "  'test accuracy': 0.6748999953269958},\n",
       " 'Numbers of exp: 21, optimizer:RMSprop, kernel: (5, 5), epochs: 10, pool_size:(3, 3)': {'Test loss': 1.0040782690048218,\n",
       "  'test accuracy': 0.6507999897003174},\n",
       " 'Numbers of exp: 22, optimizer:RMSprop, kernel: (5, 5), epochs: 20, pool_size:(2, 2)': {'Test loss': 0.8670749068260193,\n",
       "  'test accuracy': 0.718500018119812},\n",
       " 'Numbers of exp: 23, optimizer:RMSprop, kernel: (5, 5), epochs: 20, pool_size:(3, 3)': {'Test loss': 0.8547685742378235,\n",
       "  'test accuracy': 0.7049000263214111}}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd \n",
    "exp = []\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    params = re.split(', [a-zA-Z]{1}', cond)\n",
    "    params_list = [p.split(':')[1].strip() for p in params]\n",
    "    params_list.append(results[cond]['Test loss'])\n",
    "    params_list.append(results[cond]['test accuracy'])\n",
    "    exp.append(params_list)\n",
    "\n",
    "cols = ['Numbers of exp', 'optimizer', 'kernel', 'epochs', 'pool_size', 'Test loss', 'test accuracy']\n",
    "experiments = pd.DataFrame(exp, columns =cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Numbers of exp</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>kernel</th>\n",
       "      <th>epochs</th>\n",
       "      <th>pool_size</th>\n",
       "      <th>Test loss</th>\n",
       "      <th>test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SGD</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>10</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>1.779224</td>\n",
       "      <td>0.3788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SGD</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>10</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>1.961282</td>\n",
       "      <td>0.2652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>SGD</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>20</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>1.417935</td>\n",
       "      <td>0.4846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>SGD</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>20</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>1.667944</td>\n",
       "      <td>0.3921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SGD</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>10</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>1.534393</td>\n",
       "      <td>0.4416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>SGD</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>10</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>1.825028</td>\n",
       "      <td>0.3211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>SGD</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>20</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>1.315719</td>\n",
       "      <td>0.5229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>SGD</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>20</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>1.486342</td>\n",
       "      <td>0.4531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Adam</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>10</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.759319</td>\n",
       "      <td>0.7374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Adam</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>10</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>1.000064</td>\n",
       "      <td>0.6442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Adam</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>20</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.979449</td>\n",
       "      <td>0.6515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Adam</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>20</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.894187</td>\n",
       "      <td>0.6808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Adam</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>10</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>2.302588</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Adam</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>10</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>1.366850</td>\n",
       "      <td>0.5027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Adam</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>20</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>1.100681</td>\n",
       "      <td>0.6086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Adam</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>20</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>1.384432</td>\n",
       "      <td>0.5004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>10</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.898545</td>\n",
       "      <td>0.6892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>10</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>1.124711</td>\n",
       "      <td>0.6122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>20</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.761161</td>\n",
       "      <td>0.7395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>20</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.885489</td>\n",
       "      <td>0.6870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>10</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.953564</td>\n",
       "      <td>0.6749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>10</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>1.004078</td>\n",
       "      <td>0.6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>20</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.867075</td>\n",
       "      <td>0.7185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>20</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.854769</td>\n",
       "      <td>0.7049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Numbers of exp optimizer  kernel epochs pool_size  Test loss  test accuracy\n",
       "0               0       SGD  (3, 3)     10    (2, 2)   1.779224         0.3788\n",
       "1               1       SGD  (3, 3)     10    (3, 3)   1.961282         0.2652\n",
       "2               2       SGD  (3, 3)     20    (2, 2)   1.417935         0.4846\n",
       "3               3       SGD  (3, 3)     20    (3, 3)   1.667944         0.3921\n",
       "4               4       SGD  (5, 5)     10    (2, 2)   1.534393         0.4416\n",
       "5               5       SGD  (5, 5)     10    (3, 3)   1.825028         0.3211\n",
       "6               6       SGD  (5, 5)     20    (2, 2)   1.315719         0.5229\n",
       "7               7       SGD  (5, 5)     20    (3, 3)   1.486342         0.4531\n",
       "8               8      Adam  (3, 3)     10    (2, 2)   0.759319         0.7374\n",
       "9               9      Adam  (3, 3)     10    (3, 3)   1.000064         0.6442\n",
       "10             10      Adam  (3, 3)     20    (2, 2)   0.979449         0.6515\n",
       "11             11      Adam  (3, 3)     20    (3, 3)   0.894187         0.6808\n",
       "12             12      Adam  (5, 5)     10    (2, 2)   2.302588         0.1000\n",
       "13             13      Adam  (5, 5)     10    (3, 3)   1.366850         0.5027\n",
       "14             14      Adam  (5, 5)     20    (2, 2)   1.100681         0.6086\n",
       "15             15      Adam  (5, 5)     20    (3, 3)   1.384432         0.5004\n",
       "16             16   RMSprop  (3, 3)     10    (2, 2)   0.898545         0.6892\n",
       "17             17   RMSprop  (3, 3)     10    (3, 3)   1.124711         0.6122\n",
       "18             18   RMSprop  (3, 3)     20    (2, 2)   0.761161         0.7395\n",
       "19             19   RMSprop  (3, 3)     20    (3, 3)   0.885489         0.6870\n",
       "20             20   RMSprop  (5, 5)     10    (2, 2)   0.953564         0.6749\n",
       "21             21   RMSprop  (5, 5)     10    (3, 3)   1.004078         0.6508\n",
       "22             22   RMSprop  (5, 5)     20    (2, 2)   0.867075         0.7185\n",
       "23             23   RMSprop  (5, 5)     20    (3, 3)   0.854769         0.7049"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業\n",
    "1. 請試著調整各個超參數，並說明那些超參數對於結果有明顯的影響?\n",
    "    > 上述實驗 Optimizer 與 epoch 有明顯的影響\n",
    "2. CNN 與 DNN 哪個模型的參數數量比較多? 造成參數的數量不同的原因在哪?\n",
    "    > DNＮ比較多，因為池化層會減少CNN參數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8670749068260193"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['Numbers of exp: 22, optimizer:RMSprop, kernel: (5, 5), epochs: 20, pool_size:(2, 2)']['Test loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['22', 'RMSprop', '(5, 5)', '20', '(2, 2)', 1, 2, 3]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "params = 'Numbers of exp: 22, optimizer:RMSprop, kernel: (5, 5), epochs: 20, pool_size:(2, 2)'\n",
    "l = [1, 2, 3]\n",
    "param = re.split(', [a-zA-Z]{1}', params)\n",
    "a = [p.split(':')[1].strip() for p in param]\n",
    "b = a + l\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
